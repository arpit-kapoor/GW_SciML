{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5403e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998229b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base data directory: /srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/\n",
      "Raw data directory: /srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/all\n",
      "Filtered data directory: /srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/filter_all_ts\n",
      "Forcings data directory: /srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/forcings_corrected_all\n"
     ]
    }
   ],
   "source": [
    "# Define data directories\n",
    "base_data_dir = '/srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/'\n",
    "# base_data_dir = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/01_PhD/05_groundwater/data/FEFLOW/variable_density'  # Uncomment for local testing\n",
    "raw_data_dir = os.path.join(base_data_dir, 'all')\n",
    "filtered_data_dir = os.path.join(base_data_dir, 'filter_all_ts')\n",
    "# forcings_data_dir = os.path.join(base_data_dir, 'forcings_corrected')\n",
    "forcings_data_dir = os.path.join(base_data_dir, 'forcings_corrected_all')\n",
    "\n",
    "print(f\"Base data directory: {base_data_dir}\")\n",
    "print(f\"Raw data directory: {raw_data_dir}\")\n",
    "print(f\"Filtered data directory: {filtered_data_dir}\")\n",
    "print(f\"Forcings data directory: {forcings_data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679c83ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 1909\n",
      "First 3 files: ['0000.csv', '0001.csv', '0002.csv']\n",
      "Last 3 files: ['1906.csv', '1907.csv', '1908.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get and sort time series files\n",
    "ts_files = sorted(os.listdir(raw_data_dir))\n",
    "print(f\"Total number of files: {len(ts_files)}\")\n",
    "print(f\"First 3 files: {ts_files[:3]}\")\n",
    "print(f\"Last 3 files: {ts_files[-3:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37dbc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define json file path\n",
    "patch_config_json = os.path.join(base_data_dir, 'patches.json')\n",
    "\n",
    "with open(patch_config_json, 'r') as f:\n",
    "    patch_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ef86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_data_dir = os.path.join(base_data_dir, 'filter_patch_all_ts')\n",
    "patch_data_dir = os.path.join(base_data_dir, 'patch_all_ts')\n",
    "\n",
    "# data_dir = filtered_data_dir\n",
    "data_dir = raw_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f93dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing patch 1\n",
      "Patch 1 has 2117 core nodes and 630 ghost nodes\n",
      "Patch 1 has 6 neighbour patches\n",
      "Patch 1 has 1 slice group\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['mass_concentration', 'head', 'pressure']\n",
    "forcing_cols = ['mass_concentration_bc', 'head_bc', 'recharge_forcing', 'sea_level_forcing']\n",
    "coords_cols = ['X', 'Y', 'Z']\n",
    "\n",
    "patch_data = {}\n",
    "\n",
    "fillval = -999\n",
    "\n",
    "for k, v in patch_config.items():\n",
    "    \n",
    "    # Get the patch configuration\n",
    "    config = patch_config[k]\n",
    "\n",
    "    # Print patch information\n",
    "    print(f\"\\nProcessing patch {k}\")\n",
    "    print(f\"Patch {k} has {len(config['core_nodes'])} core nodes and {len(config['ghost_nodes'])} ghost nodes\")\n",
    "    print(f\"Patch {k} has {len(config['neighbour_patches'])} neighbour patches\")\n",
    "    print(f\"Patch {k} has {config['slice_group']} slice group\")\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    core_patch_data = []\n",
    "    ghost_patch_data = []\n",
    "\n",
    "    core_forcings_data = []\n",
    "    ghost_forcings_data = []\n",
    "\n",
    "    # Load the data#\n",
    "    for ts_file in ts_files:\n",
    "        ts_df = pd.read_csv(os.path.join(data_dir, ts_file))\n",
    "        core_patch_data.append(ts_df.loc[ts_df['node'].isin(config['core_nodes']), target_cols].values)\n",
    "        ghost_patch_data.append(ts_df.loc[ts_df['node'].isin(config['ghost_nodes']), target_cols].values)\n",
    "        \n",
    "        ts_forcings_df = pd.read_csv(os.path.join(forcings_data_dir, ts_file))\n",
    "        core_forcings_data.append(ts_forcings_df.loc[ts_forcings_df['node'].isin(config['core_nodes']), forcing_cols].values)\n",
    "        ghost_forcings_data.append(ts_forcings_df.loc[ts_forcings_df['node'].isin(config['ghost_nodes']), forcing_cols].values)\n",
    "\n",
    "        \n",
    "    # Convert to numpy arrays\n",
    "    core_patch_data = np.nan_to_num(np.array(core_patch_data))\n",
    "    ghost_patch_data = np.nan_to_num(np.array(ghost_patch_data))\n",
    "    core_forcings_data = np.nan_to_num(np.array(core_forcings_data))\n",
    "    ghost_forcings_data = np.nan_to_num(np.array(ghost_forcings_data))\n",
    "    \n",
    "    core_coords = ts_df.loc[ts_df['node'].isin(config['core_nodes']), coords_cols].values\n",
    "    ghost_coords = ts_df.loc[ts_df['node'].isin(config['ghost_nodes']), coords_cols].values\n",
    "\n",
    "    # Create directory for patch data\n",
    "    patch_dir_path = os.path.join(patch_data_dir, f'patch_{int(k):03d}')\n",
    "    os.makedirs(patch_dir_path, exist_ok=True)\n",
    "\n",
    "    # Save the data\n",
    "    np.save(os.path.join(patch_dir_path, 'core_obs.npy'), core_patch_data)\n",
    "    np.save(os.path.join(patch_dir_path, 'ghost_obs.npy'), ghost_patch_data)\n",
    "    np.save(os.path.join(patch_dir_path, 'core_coords.npy'), core_coords)\n",
    "    np.save(os.path.join(patch_dir_path, 'ghost_coords.npy'), ghost_coords)\n",
    "    np.save(os.path.join(patch_dir_path, 'core_forcings.npy'), core_forcings_data)\n",
    "    np.save(os.path.join(patch_dir_path, 'ghost_forcings.npy'), ghost_forcings_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef69c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_arr = []\n",
    "\n",
    "\n",
    "# for k, v in patch_config.items():\n",
    "\n",
    "#     patch_dir_path = os.path.join(filter_patch_data_dir, f'patch_{int(k):03d}')\n",
    "\n",
    "#     core_forcings_data = np.load(os.path.join(patch_dir_path, 'core_forcings.npy'))\n",
    "#     ghost_forcings_data = np.load(os.path.join(patch_dir_path, 'ghost_forcings.npy'))\n",
    "\n",
    "#     # print((~np.isnan(core_forcings_data)).sum()/core_forcings_data.flatten().shape[0])\n",
    "#     concat_arr.append(core_forcings_data.reshape(-1, 4))\n",
    "\n",
    "# concat_arr = np.concatenate(concat_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f51c6-3db8-47c8-80d8-a40cd3cb5e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (torch-env)",
   "language": "python",
   "name": "conda_torch-env_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
