{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c427493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d133ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/processed/2d_plane_data'\n",
    "\n",
    "sea_level_csv = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/simulation_files/SeaLevelDataPeaksHL.csv'\n",
    "# sea_level_csv = '/Users/arpitkapoor/Downloads/SeaLevelDataPeaksHL.csv'\n",
    "\n",
    "\n",
    "skip_factor = 2  # Process every 2nd timestep for faster processing\n",
    "\n",
    "times = pd.read_csv(sea_level_csv, header=None, names=['time', 'sealevel'])['time'].values[::skip_factor]\n",
    "times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc9ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data_dirs = sorted(os.listdir(data_path))\n",
    "sorted_data_dirs = [d for d in sorted_data_dirs if d.startswith('timestep_')]\n",
    "sorted_data_dirs  = sorted_data_dirs[::skip_factor]  # Skip timesteps for faster processing\n",
    "len(sorted_data_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9750439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:18<00:00, 52.49it/s]\n"
     ]
    }
   ],
   "source": [
    "N_planes = 32\n",
    "\n",
    "plane_data_all_timesteps = {p: [] for p in range(N_planes)}\n",
    "bc_data_all_timesteps = {p: [] for p in range(N_planes)}\n",
    "\n",
    "bc_nodes_for_plane = {}\n",
    "\n",
    "\n",
    "for t  in tqdm(range(len(sorted_data_dirs))):\n",
    "    d = sorted_data_dirs[t]\n",
    "    ts_dir = os.path.join(data_path, d)\n",
    "    sorted_planes_dir = sorted(os.listdir(ts_dir))\n",
    "    sorted_planes_dir = [os.path.join(ts_dir, f) for f in sorted_planes_dir]\n",
    "\n",
    "    for p, f in enumerate(sorted_planes_dir):\n",
    "        \n",
    "        plane_data = np.load(os.path.join(f, 'plane_data.npz'))\n",
    "        S = plane_data['S']\n",
    "        Z = plane_data['Z']\n",
    "        X = plane_data['X']\n",
    "        Y = plane_data['Y']\n",
    "        T = np.ones_like(X) * times[t]\n",
    "        head_m = plane_data['head_m']\n",
    "        mass_conc_mg_l = plane_data['mass_conc_mg_l']\n",
    "        # print(f\" Processing plane {p} at timestep {d.split('_')[-1]} with shapes: X-{X.shape}, Y-{Y.shape}, Z-{Z.shape}, T-{T.shape}, head_m-{head_m.shape}, mass_conc_mg_l-{mass_conc_mg_l.shape}\")\n",
    "        stacked_plane = np.stack([S, Z, T, X, Y, head_m, mass_conc_mg_l], axis=-1)\n",
    "\n",
    "        plane_data_all_timesteps[p].append(stacked_plane)\n",
    "\n",
    "        bc_data = np.load(os.path.join(f, 'bc_data.npz'))\n",
    "        bc_node_idx = bc_data['node_idx']\n",
    "        bc_S = bc_data['S']\n",
    "        bc_Z = bc_data['Z']\n",
    "        bc_T = np.ones_like(bc_node_idx) * times[t]\n",
    "        bc_head = bc_data['head']\n",
    "        bc_mass_conc = bc_data['mass_conc']\n",
    "        \n",
    "        # Assertion to ensure bc arrays have the same length\n",
    "        if not len(bc_S) == len(bc_Z) == len(bc_head) == len(bc_mass_conc):\n",
    "            print(f\" Plane {p} failed assertion! Boundary condition arrays have mismatched lengths\")\n",
    "            continue\n",
    "\n",
    "        if t == 0:\n",
    "            bc_nodes_for_plane[p] = bc_node_idx.astype(np.int32)\n",
    "        else:\n",
    "            bc_nodes_for_plane[p] = np.intersect1d(bc_nodes_for_plane[p], bc_node_idx.astype(np.int32))\n",
    "\n",
    "        stacked_bc = np.stack([bc_node_idx, bc_S, bc_Z, bc_T, \n",
    "                               bc_head, bc_mass_conc], axis=-1)\n",
    "        bc_data_all_timesteps[p].append(stacked_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc15351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 63.64it/s] \n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(N_planes)):\n",
    "    plane_data_p = plane_data_all_timesteps[p]\n",
    "    plane_data_all_timesteps[p] = np.stack(plane_data_p, axis=0)\n",
    "    # print(f\" Plane {p} data shape across all timesteps: {plane_data_all_timesteps[p].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79301cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 66.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for p in tqdm(range(N_planes)):\n",
    "    bc_list = bc_data_all_timesteps[p]\n",
    "    n_bc = len(bc_list)\n",
    "\n",
    "    bc_data_for_selected_nodes = []\n",
    "\n",
    "    for t in range(n_bc):\n",
    "        bc_data_for_p_at_t = bc_data_all_timesteps[p][t]\n",
    "        bc_nodes_for_p = bc_nodes_for_plane[p]\n",
    "\n",
    "        # Filter bc_data_for_p_at_t to only include rows where node_idx is in bc_nodes_for_p\n",
    "        mask = np.isin(bc_data_for_p_at_t[:, 0], bc_nodes_for_p)\n",
    "        bc_data_for_selected_nodes.append(bc_data_for_p_at_t[mask])\n",
    "    \n",
    "    bc_data_all_timesteps[p] = np.stack(bc_data_for_selected_nodes, axis=0)\n",
    "    # print(f\" Plane {p}: Cleaned BC data shape across all timesteps: {bc_data_all_timesteps[p].shape}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c527403",
   "metadata": {},
   "source": [
    "Write cleaned up data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f67f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir\n",
    "outdir = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/processed/2d_plane_data_cleaned'\n",
    "os.makedirs(outdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a23b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing data for plane 0 to /Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/processed/2d_plane_data_cleaned/plane_00 ...\n",
      "  Input Geom shape: (326, 3), Input data shape: (955, 326, 2)\n",
      "  Latent Geom shape: (32, 32, 3), Latent inputs shape: (955, 32, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "for p in range(N_planes):\n",
    "    plane_dir = os.path.join(outdir, f'plane_{p:02d}')\n",
    "    os.makedirs(plane_dir, exist_ok=True)\n",
    "\n",
    "    # BC data\n",
    "    # Input Geom - S, Z, T\n",
    "    input_geom = bc_data_all_timesteps[p][0,..., 1:4]\n",
    "    input_data = bc_data_all_timesteps[p][..., 4:]\n",
    "    lantent_geom = plane_data_all_timesteps[p][0,..., :3]\n",
    "\n",
    "    # Latent inputs\n",
    "    latent_inputs = plane_data_all_timesteps[p][..., 3:]\n",
    "\n",
    "    print(f\"\\nWriting data for plane {p} to {plane_dir} ...\")\n",
    "    print(f\"  Input Geom shape: {input_geom.shape}, Input data shape: {input_data.shape}\")\n",
    "    print(f\"  Latent Geom shape: {lantent_geom.shape}, Latent inputs shape: {latent_inputs.shape}\")\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6425032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 116 time sequences with alpha=16\n",
      "\n",
      "\n",
      "First few sequences: [(0, 16, 32), (8, 24, 40), (16, 32, 48)] \n",
      " times: [[ 0.         13.91666667 26.91666667]\n",
      " [ 7.91666667 20.75       34.75      ]\n",
      " [13.91666667 26.91666667 42.41666667]]\n",
      "\n",
      "\n",
      "Last few sequences: [(904, 920, 936), (912, 928, 944), (920, 936, 952)] \n",
      " times: [[859.5416667 875.5833333 891.4583333]\n",
      " [867.4166667 883.5       899.4583333]\n",
      " [875.5833333 891.4583333 906.3333333]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 5649.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sequences per plane: 116\n",
      "Total planes: 32\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences for all planes\n",
    "input_sequences = {p: {'input_geom': [], 'input_data': [], 'latent_geom': [], 'latent_features': []} for p in range(N_planes)}\n",
    "output_sequences = {p: {'latent_geom': [], 'latent_features': []} for p in range(N_planes)}\n",
    "\n",
    "alpha = 16 # sequence length for input and output\n",
    "\n",
    "# Generate time sequences\n",
    "n_timesteps = len(sorted_data_dirs)\n",
    "ts = [(i, i + alpha, i + 2 * alpha) for i in range(0, n_timesteps - 2 * alpha + 1, alpha//2)]\n",
    "print(f\"Generated {len(ts)} time sequences with alpha={alpha}\")\n",
    "print(f\"\\n\\nFirst few sequences: {ts[:3]} \\n times: {times[[ts[i] for i in range(min(3, len(ts)))]]}\")\n",
    "print(f\"\\n\\nLast few sequences: {ts[-3:]} \\n times: {times[[ts[i] for i in range(max(0, len(ts)-3), len(ts))]]}\")\n",
    "\n",
    "for p in tqdm(range(N_planes)):\n",
    "    # BC data for this plane\n",
    "    bc_data = bc_data_all_timesteps[p]  # shape: (n_timesteps, n_bc_nodes, 6)\n",
    "    # Plane data for this plane\n",
    "    plane_data = plane_data_all_timesteps[p]  # shape: (n_timesteps, n_nodes, 7)\n",
    "    \n",
    "    for t_start, t_mid, t_end in ts:\n",
    "        # Input sequence: [t_start:t_mid]\n",
    "        input_geom_seq = bc_data[t_start:t_mid, ..., 1:4].reshape(-1, 3)  # (alpha, n_bc_nodes, 3) - S, Z, T\n",
    "        input_data_seq = bc_data[t_start:t_mid, ..., 4:].reshape(-1, 2)  # (alpha, n_bc_nodes, 2) - head, mass_conc\n",
    "        \n",
    "        latent_geom_seq = plane_data[t_start:t_mid, ..., :3]  # (alpha, n_nodes, 3) - S, Z, T\n",
    "        latent_features_seq = plane_data[t_start:t_mid, ..., 3:]  # (alpha, n_nodes, 4) - X, Y, head, mass_conc\n",
    "        \n",
    "        # Output sequence: [t_mid:t_end]\n",
    "        output_latent_geom_seq = plane_data[t_mid:t_end, ..., :3]  # (alpha, n_nodes, 3)\n",
    "        output_latent_features_seq = plane_data[t_mid:t_end, ..., 3:]  # (alpha, n_nodes, 4)\n",
    "        \n",
    "        # Store sequences\n",
    "        input_sequences[p]['input_geom'].append(input_geom_seq)\n",
    "        input_sequences[p]['input_data'].append(input_data_seq)\n",
    "        input_sequences[p]['latent_geom'].append(latent_geom_seq)\n",
    "        input_sequences[p]['latent_features'].append(latent_features_seq)\n",
    "        \n",
    "        output_sequences[p]['latent_geom'].append(output_latent_geom_seq)\n",
    "        output_sequences[p]['latent_features'].append(output_latent_features_seq)\n",
    "\n",
    "# Convert lists to numpy arrays for each plane and field\n",
    "for p in range(N_planes):\n",
    "    for key in input_sequences[p]:\n",
    "        input_sequences[p][key] = np.array(input_sequences[p][key])\n",
    "    for key in output_sequences[p]:\n",
    "        output_sequences[p][key] = np.array(output_sequences[p][key])\n",
    "\n",
    "print(f\"\\nTotal sequences per plane: {len(ts)}\")\n",
    "print(f\"Total planes: {N_planes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a0467a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116, 5216, 3), (116, 5216, 2), (116, 16, 32, 32, 3), (116, 16, 32, 32, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[0]['input_geom'].shape, input_sequences[0]['input_data'].shape, output_sequences[0]['latent_geom'].shape, output_sequences[0]['latent_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f081ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86724964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/10_Katana/04_groundwater/GW_SciML/')\n",
    "from src.models.neuralop.gno import GNOBlock\n",
    "from src.models.neuralop.fno import FNOBlocks\n",
    "from src.models.neuralop.channel_mlp import ChannelMLP\n",
    "\n",
    "# Model configuration parameters\n",
    "coord_dim = 3  # 3D: S, Z, T (time as dimension)\n",
    "n_target_cols = 2  # head and mass_concentration\n",
    "\n",
    "# GNO and FNO parameters\n",
    "gno_radius = 0.15\n",
    "gno_out_channels = n_target_cols  # 10 * 2 = 20\n",
    "gno_channel_mlp_layers = [16, 32, 16]\n",
    "\n",
    "fno_n_layers = 4\n",
    "fno_n_modes = (6, 8, 8)  # 3D modes (S, Z, T)\n",
    "fno_hidden_channels = 64\n",
    "lifting_channels = 64\n",
    "out_channels = n_target_cols  # 10 * 2 = 20\n",
    "\n",
    "latent_query_dims = (alpha, 32, 32)  # 3D latent grid with time\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a8e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GFNO(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Input GNO\n",
    "        gno_coord_dim=3,\n",
    "        gno_radius=0.03,\n",
    "        gno_pos_embed_type='transformer',\n",
    "        gno_pos_embed_channels=32,\n",
    "        gno_pos_embed_max_positions=10000,\n",
    "        gno_channel_mlp_layers=[64, 64, 64],\n",
    "        gno_channel_mlp_non_linearity=F.gelu,\n",
    "        gno_out_channels=3,\n",
    "        # Latent features\n",
    "        latent_feature_channels=None,\n",
    "        # FNO\n",
    "        fno_n_layers=4,\n",
    "        fno_n_modes=(16, 16, 16),\n",
    "        fno_hidden_channels=128,\n",
    "        fno_skip_fno_bias=False,\n",
    "        fno_fft_norm=\"forward\",\n",
    "        fno_rank=1.0,\n",
    "        fno_max_n_modes=None,\n",
    "        fno_non_linearity=F.gelu,\n",
    "        # Lifting\n",
    "        lifting_channels=128,\n",
    "        # Projection\n",
    "        projection_channel_ratio=4,\n",
    "        out_channels=1,\n",
    "        # Neighbor search settings\n",
    "        use_open3d_neighbor_search=None,\n",
    "    ):\n",
    "        super(GFNO, self).__init__()\n",
    "\n",
    "        # Determine whether to use open3d neighbor search based on coordinate dimension\n",
    "        if use_open3d_neighbor_search is None:\n",
    "            # Only use open3d for 3D coordinates\n",
    "            use_open3d_neighbor_search = (gno_coord_dim == 3)\n",
    "\n",
    "        self.gno_coord_dim = gno_coord_dim\n",
    "        self.gno_radius = gno_radius\n",
    "        self.gno_pos_embed_type = gno_pos_embed_type\n",
    "        self.gno_pos_embed_channels = gno_pos_embed_channels\n",
    "        self.gno_pos_embed_max_positions = gno_pos_embed_max_positions\n",
    "        self.gno_channel_mlp_layers = gno_channel_mlp_layers\n",
    "        self.gno_channel_mlp_non_linearity = gno_channel_mlp_non_linearity\n",
    "        self.gno_out_channels = gno_out_channels\n",
    "        self.latent_feature_channels = latent_feature_channels\n",
    "\n",
    "        self.gno = GNOBlock(\n",
    "            in_channels=0,\n",
    "            out_channels=gno_out_channels,\n",
    "            coord_dim=gno_coord_dim,\n",
    "            radius=gno_radius,\n",
    "            pos_embedding_type=gno_pos_embed_type,\n",
    "            pos_embedding_channels=gno_pos_embed_channels,\n",
    "            pos_embedding_max_positions=gno_pos_embed_max_positions,\n",
    "            reduction='mean',\n",
    "            weighting_fn=None,\n",
    "            channel_mlp_layers=gno_channel_mlp_layers,\n",
    "            channel_mlp_non_linearity=gno_channel_mlp_non_linearity,\n",
    "            transform_type='linear',\n",
    "            use_open3d_neighbor_search=use_open3d_neighbor_search,\n",
    "            use_torch_scatter_reduce=False\n",
    "        )\n",
    "        \n",
    "        # Store additional attributes needed for forward pass\n",
    "        self.fno_hidden_channels = fno_hidden_channels\n",
    "        self.in_coord_dim_reverse_order = list(range(2, gno_coord_dim + 2))  # For permute operation\n",
    "        self.adain_pos_embed = None  # Placeholder for adaptive instance norm embedding\n",
    "        self.fno_norm = None  # Placeholder for FNO normalization\n",
    "        self.out_gno_tanh = None  # Placeholder for output GNO tanh activation\n",
    "\n",
    "        if latent_feature_channels is not None:\n",
    "            self.fno_in_channels = gno_out_channels + latent_feature_channels\n",
    "        else:\n",
    "            self.fno_in_channels = gno_out_channels\n",
    "\n",
    "        # Define FNO blocks\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            n_layers=fno_n_layers,\n",
    "            n_modes=fno_n_modes,\n",
    "            hidden_channels=fno_hidden_channels,\n",
    "            skip_fno_bias=fno_skip_fno_bias,\n",
    "            fft_norm=fno_fft_norm,\n",
    "            rank=fno_rank,\n",
    "            max_n_modes=fno_max_n_modes,\n",
    "            non_linearity=fno_non_linearity,\n",
    "        )\n",
    "\n",
    "        # Define lifting layer\n",
    "        self.lifting_channels = lifting_channels\n",
    "        self.lifting = ChannelMLP(\n",
    "            in_channels=self.fno_in_channels,\n",
    "            hidden_channels=self.lifting_channels,\n",
    "            out_channels=fno_hidden_channels,\n",
    "            n_layers=2\n",
    "        )\n",
    "\n",
    "\n",
    "        # Define projection layer\n",
    "        self.projection_channel_ratio = projection_channel_ratio\n",
    "        self.projection_channels = projection_channel_ratio * fno_hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.projection = ChannelMLP(\n",
    "            in_channels=fno_hidden_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            hidden_channels=self.projection_channels,\n",
    "            n_layers=2,\n",
    "            # n_dim=1,\n",
    "            non_linearity=fno_non_linearity\n",
    "        )\n",
    "\n",
    "    def latent_embedding(self, in_p, ada_in=None):\n",
    "\n",
    "        # in_p : (batch, n_1 , ... , n_k, in_channels + k)\n",
    "        # ada_in : (fno_ada_in_dim, )\n",
    "\n",
    "        # permute (b, n_1, ..., n_k, c) -> (b,c, n_1,...n_k)\n",
    "        in_p = in_p.permute(0, len(in_p.shape)-1, *list(range(1,len(in_p.shape)-1)))\n",
    "        #Update Ada IN embedding    \n",
    "        if ada_in is not None:\n",
    "            if ada_in.ndim == 2:\n",
    "                ada_in = ada_in.squeeze(0)\n",
    "            if self.adain_pos_embed is not None:\n",
    "                ada_in_embed = self.adain_pos_embed(ada_in.unsqueeze(0)).squeeze(0)\n",
    "            else:\n",
    "                ada_in_embed = ada_in\n",
    "            if self.fno_norm == \"ada_in\":\n",
    "                self.fno_blocks.set_ada_in_embeddings(ada_in_embed)\n",
    "\n",
    "        #Apply FNO blocks\n",
    "        in_p = self.lifting(in_p)\n",
    "\n",
    "        # for idx in range(self.fno_blocks.n_layers):\n",
    "        in_p = self.fno_blocks(in_p)\n",
    "\n",
    "        return in_p \n",
    "\n",
    "    def forward(self, input_geom, latent_queries, x=None, latent_features=None, ada_in=None, **kwargs):\n",
    "\n",
    "        if x is None:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "        \n",
    "        if latent_features is not None:\n",
    "            assert self.latent_feature_channels is not None,\\\n",
    "                  \"if passing latent features, latent_feature_channels must be set.\"\n",
    "            assert latent_features.shape[-1] == self.latent_feature_channels\n",
    "\n",
    "            # batch, n_gridpts_1, .... n_gridpts_n, gno_coord_dim\n",
    "            assert latent_features.ndim == self.gno_coord_dim + 2,\\\n",
    "                f\"Latent features must be of shape (batch, n_gridpts_1, ...n_gridpts_n, gno_coord_dim), got {latent_features.shape}\"\n",
    "            # latent features must have the same shape (except channels) as latent_queries \n",
    "            if latent_features.shape[0] != batch_size:\n",
    "                if latent_features.shape[0] == 1:\n",
    "                    latent_features = latent_features.repeat(batch_size, *[1]*(latent_features.ndim-1))\n",
    "\n",
    "\n",
    "        # Squeeze batch dim if batch_size == 1\n",
    "        if (input_geom.shape[0] == 1 and input_geom.ndim == 3) or input_geom.ndim == 2:\n",
    "            input_geom = input_geom.squeeze(0) \n",
    "            latent_queries = latent_queries.squeeze(0)\n",
    "\n",
    "            # Pass through input GNOBlock \n",
    "            in_p = self.gno(y=input_geom,\n",
    "                            x=latent_queries.view((-1, \n",
    "                                                   latent_queries.shape[-1])),\n",
    "                            f_y=x)\n",
    "        elif input_geom.shape[0] == batch_size:\n",
    "            in_p_list = []\n",
    "            for b in range(batch_size):\n",
    "                in_p_b = self.gno(y=input_geom[b],\n",
    "                                 x=latent_queries[b].view((-1, \n",
    "                                                           latent_queries.shape[-1])),\n",
    "                                 f_y=x[b] if x is not None else None)\n",
    "                in_p_list.append(in_p_b)\n",
    "            in_p = torch.stack(in_p_list, dim=0)\n",
    "        else:\n",
    "            raise ValueError(f\"input_geom batch size {input_geom.shape[0]} does not match x batch size {batch_size}\")\n",
    "        \n",
    "        print(in_p.shape)\n",
    "        \n",
    "        grid_shape = latent_queries.shape[:-1] # disregard positional encoding dim\n",
    "        \n",
    "        # shape (batch_size, grid1, ...gridn, -1)\n",
    "        in_p = in_p.view((batch_size, *grid_shape, -1))\n",
    "        \n",
    "        if latent_features is not None:\n",
    "            in_p = torch.cat((in_p, latent_features), dim=-1)\n",
    "        # take apply fno in latent space\n",
    "        latent_embed = self.latent_embedding(in_p=in_p, \n",
    "                                             ada_in=ada_in)\n",
    "\n",
    "        # Integrate latent space to output queries\n",
    "        #latent_embed shape (b, c, n_1, n_2, ..., n_k)\n",
    "        batch_size = latent_embed.shape[0]\n",
    "        # permute to (b, n_1, n_2, ...n_k, c)\n",
    "        # then reshape to (b, n_1 * n_2 * ...n_k, out_channels)\n",
    "        latent_embed = latent_embed.permute(0, *self.in_coord_dim_reverse_order, 1)\n",
    "        \n",
    "        if self.out_gno_tanh in ['latent_embed', 'both']:\n",
    "            latent_embed = torch.tanh(latent_embed)\n",
    "\n",
    "        # Project pointwise to out channels\n",
    "        latent_embed = latent_embed.permute(0, 4, 1, 2, 3)\n",
    "        out = self.projection(latent_embed)\n",
    "        out = out.permute(0, *self.in_coord_dim_reverse_order, 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7352c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfno = GFNO(\n",
    "    gno_coord_dim=coord_dim,\n",
    "    gno_radius=gno_radius,\n",
    "    gno_out_channels=gno_out_channels,\n",
    "    gno_channel_mlp_layers=gno_channel_mlp_layers,\n",
    "    latent_feature_channels=4,  # X, Y, head, mass_conc\n",
    "    fno_n_layers=fno_n_layers,\n",
    "    fno_n_modes=fno_n_modes,\n",
    "    fno_hidden_channels=fno_hidden_channels,\n",
    "    lifting_channels=lifting_channels,\n",
    "    out_channels=out_channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ca820",
   "metadata": {},
   "source": [
    "### Use GFNO from Module\n",
    "\n",
    "Now you can import GFNO directly from the models module instead of defining it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cbabd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFNO model created with 7909988 parameters\n"
     ]
    }
   ],
   "source": [
    "# Import GFNO from the models module\n",
    "from src.models import GFNO\n",
    "\n",
    "# Create GFNO instance using the imported class\n",
    "gfno_from_module = GFNO(\n",
    "    gno_coord_dim=coord_dim,\n",
    "    gno_radius=gno_radius,\n",
    "    gno_out_channels=gno_out_channels,\n",
    "    gno_channel_mlp_layers=gno_channel_mlp_layers,\n",
    "    latent_feature_channels=4,  # X, Y, head, mass_conc\n",
    "    fno_n_layers=fno_n_layers,\n",
    "    fno_n_modes=fno_n_modes,\n",
    "    fno_hidden_channels=fno_hidden_channels,\n",
    "    lifting_channels=lifting_channels,\n",
    "    out_channels=out_channels\n",
    ").to(device)\n",
    "\n",
    "print(f\"GFNO model created with {sum(p.numel() for p in gfno_from_module.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e92f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Geom sample shape: torch.Size([64, 5216, 3])\n",
      "Input Data sample shape: torch.Size([64, 5216, 2])\n",
      "Latent Geom sample shape: torch.Size([64, 16, 32, 32, 3])\n",
      "Latent Features sample shape: torch.Size([64, 16, 32, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "input_geom_sample = torch.tensor(input_sequences[0]['input_geom'][:64], dtype=torch.float32)\n",
    "input_data_sample = torch.tensor(input_sequences[0]['input_data'][:64], dtype=torch.float32)\n",
    "latent_geom_sample = torch.tensor(input_sequences[0]['latent_geom'][:64], dtype=torch.float32)\n",
    "latent_features_sample = torch.tensor(input_sequences[0]['latent_features'][:64], dtype=torch.float32)\n",
    "\n",
    "# Fill nan values with -999\n",
    "input_geom_sample = torch.nan_to_num(input_geom_sample, nan=-999.0)\n",
    "input_data_sample = torch.nan_to_num(input_data_sample, nan=-999.0)\n",
    "latent_geom_sample = torch.nan_to_num(latent_geom_sample, nan=-999.0)\n",
    "latent_features_sample = torch.nan_to_num(latent_features_sample, nan=-999.0)\n",
    "\n",
    "print(f\"Input Geom sample shape: {input_geom_sample.shape}\")  # (alpha, n_bc_nodes, 3)\n",
    "print(f\"Input Data sample shape: {input_data_sample.shape}\")  # (alpha, n_bc_nodes, 2)\n",
    "print(f\"Latent Geom sample shape: {latent_geom_sample.shape}\")  # (alpha, n_nodes, 3)\n",
    "print(f\"Latent Features sample shape: {latent_features_sample.shape}\")  # (alpha, n_nodes, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594b8710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16384, 2])\n",
      "CPU times: user 20.5 s, sys: 4.09 s, total: 24.6 s\n",
      "Wall time: 19.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 32, 32, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gfno(input_geom=input_geom_sample.to(device)[0],\n",
    "     x = input_data_sample.to(device),\n",
    "     latent_queries=latent_geom_sample.to(device)[0],\n",
    "     latent_features=latent_features_sample.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db5669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a740372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4e259b8",
   "metadata": {},
   "source": [
    "## Create Dataset and DataLoader\n",
    "\n",
    "Now let's create a dataset and dataloader using the plane data we've prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dd014cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GWPlaneDataset with 3712 sequences across 32 planes\n",
      "\n",
      "Dataset created with 3712 total sequences\n",
      "Sample shapes:\n",
      "  plane_id: 0\n",
      "  input_geom: torch.Size([5216, 3])\n",
      "  input_data: torch.Size([5216, 2])\n",
      "  latent_geom: torch.Size([16, 32, 32, 3])\n",
      "  latent_features: torch.Size([16, 32, 32, 4])\n",
      "  output_latent_geom: torch.Size([16, 32, 32, 3])\n",
      "  output_latent_features: torch.Size([16, 32, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data.plane_dataset import GWPlaneDataset\n",
    "from src.data.batch_sampler import PatchBatchSampler  # Works for both patches and planes!\n",
    "\n",
    "# Create the dataset\n",
    "dataset = GWPlaneDataset(\n",
    "    input_sequences=input_sequences,\n",
    "    output_sequences=output_sequences,\n",
    "    fill_nan_value=-999.0\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset created with {len(dataset)} total sequences\")\n",
    "print(f\"Sample shapes:\")\n",
    "sample = dataset[0]\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38abb3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building patch groups (one-time operation)...\n",
      "Found 32 patches with 3712 total samples\n",
      "Patch sizes: min=116, max=116, avg=116.0\n",
      "Pre-built 64 batches\n",
      "\n",
      "Batch sampler created:\n",
      "  Total batches: 64\n",
      "  Batch size: 64\n",
      "\n",
      "DataLoader created with 64 batches\n"
     ]
    }
   ],
   "source": [
    "# Create the batch sampler\n",
    "# This ensures all samples from the same plane are in the same batch\n",
    "batch_size = 64\n",
    "batch_sampler = PatchBatchSampler(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle_within_batches=True,  # Shuffle sequences within each batch\n",
    "    shuffle_patches=True,  # Shuffle the order of planes\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch sampler created:\")\n",
    "print(f\"  Total batches: {len(batch_sampler)}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_sampler=batch_sampler,\n",
    "    num_workers=0  # Set to > 0 for parallel data loading\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader created with {len(dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4cf0413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataloader - fetching first 3 batches:\n",
      "\n",
      "Batch 1:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26]\n",
      "  Unique planes: [26] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 320, 3])\n",
      "  Input data shape: torch.Size([64, 320, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n",
      "Batch 1:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26]\n",
      "  Unique planes: [26] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 320, 3])\n",
      "  Input data shape: torch.Size([64, 320, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n",
      "Batch 2:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29]\n",
      "  Unique planes: [29] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 320, 3])\n",
      "  Input data shape: torch.Size([64, 320, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n",
      "Batch 3:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  Unique planes: [0] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 5216, 3])\n",
      "  Input data shape: torch.Size([64, 5216, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n",
      "Batch 2:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29]\n",
      "  Unique planes: [29] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 320, 3])\n",
      "  Input data shape: torch.Size([64, 320, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n",
      "Batch 3:\n",
      "  Batch size (actual): 64\n",
      "  Plane IDs in batch: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  Unique planes: [0] (should be single plane)\n",
      "  Input geom shape: torch.Size([64, 5216, 3])\n",
      "  Input data shape: torch.Size([64, 5216, 2])\n",
      "  Latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "  Output latent geom shape: torch.Size([64, 16, 32, 32, 3])\n",
      "  Output latent features shape: torch.Size([64, 16, 32, 32, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the dataloader by fetching a few batches\n",
    "print(\"Testing dataloader - fetching first 3 batches:\\n\")\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    \n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(f\"  Batch size (actual): {len(batch['plane_id'])}\")\n",
    "    print(f\"  Plane IDs in batch: {batch['plane_id'].numpy()}\")\n",
    "    print(f\"  Unique planes: {torch.unique(batch['plane_id']).numpy()} (should be single plane)\")\n",
    "    print(f\"  Input geom shape: {batch['input_geom'].shape}\")\n",
    "    print(f\"  Input data shape: {batch['input_data'].shape}\")\n",
    "    print(f\"  Latent geom shape: {batch['latent_geom'].shape}\")\n",
    "    print(f\"  Latent features shape: {batch['latent_features'].shape}\")\n",
    "    print(f\"  Output latent geom shape: {batch['output_latent_geom'].shape}\")\n",
    "    print(f\"  Output latent features shape: {batch['output_latent_features'].shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec5afd",
   "metadata": {},
   "source": [
    "## Save Data to Disk (Optional)\n",
    "\n",
    "If you want to use `GWPlaneDatasetFromFiles` for on-disk loading, save the data in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to disk in format expected by GWPlaneDatasetFromFiles\n",
    "save_to_disk = False  # Set to True to save\n",
    "\n",
    "if save_to_disk:\n",
    "    output_data_dir = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/processed/2d_plane_sequences'\n",
    "    os.makedirs(output_data_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving plane data to {output_data_dir}...\")\n",
    "    \n",
    "    for p in tqdm(range(N_planes)):\n",
    "        plane_dir = os.path.join(output_data_dir, f'plane_{p:02d}')\n",
    "        os.makedirs(plane_dir, exist_ok=True)\n",
    "        \n",
    "        # Save all data for this plane\n",
    "        np.save(os.path.join(plane_dir, 'input_geom.npy'), input_sequences[p]['input_geom'])\n",
    "        np.save(os.path.join(plane_dir, 'input_data.npy'), input_sequences[p]['input_data'])\n",
    "        np.save(os.path.join(plane_dir, 'latent_geom.npy'), input_sequences[p]['latent_geom'])\n",
    "        np.save(os.path.join(plane_dir, 'latent_features.npy'), input_sequences[p]['latent_features'])\n",
    "        np.save(os.path.join(plane_dir, 'output_latent_geom.npy'), output_sequences[p]['latent_geom'])\n",
    "        np.save(os.path.join(plane_dir, 'output_latent_features.npy'), output_sequences[p]['latent_features'])\n",
    "    \n",
    "    print(f\"Data saved successfully!\")\n",
    "    \n",
    "    # Now you can load using GWPlaneDatasetFromFiles\n",
    "    # from src.data.plane_dataset import GWPlaneDatasetFromFiles\n",
    "    # dataset_from_disk = GWPlaneDatasetFromFiles(output_data_dir)\n",
    "else:\n",
    "    print(\"Skipping save to disk (set save_to_disk=True to save)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
