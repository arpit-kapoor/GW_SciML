{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8030b85d-5bac-473a-b92d-adebaff59b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559976f5-9134-4459-97c7-d997b6d0d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from src.data.dataset import GWDataset, GWGridDataset, Normalize\n",
    "from src.model.handler import ModelHandler\n",
    "from src.model.neuralop.fno import FNO\n",
    "from src.model.neuralop.losses import LpLoss, H1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf31ff43-50ac-4939-88a4-d1a2cdc9bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_data_dir = '/srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density/'\n",
    "base_data_dir = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/01_PhD/05_groundwater/data/FEFLOW/variable_density/'\n",
    "interpolated_data_dir = os.path.join(base_data_dir, 'interpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56e031d-b1f3-4015-962a-c21c9ec0fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_mean = np.array([-0.5474])\n",
    "_std = np.array([0.6562])\n",
    "input_transform = Normalize(mean=_mean, std=_std)\n",
    "output_transform = Normalize(mean=_mean, std=_std)\n",
    "\n",
    "in_window_size = 5\n",
    "out_window_size = 5\n",
    "val_ratio = 0.3\n",
    "batch_size = 32\n",
    "\n",
    "fill_value = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3e8832-85a9-477b-bd6b-5a59c8126ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = GWGridDataset(data_path=interpolated_data_dir,\n",
    "                         dataset='train', val_ratio=val_ratio,\n",
    "                         in_window_size=in_window_size,\n",
    "                         out_window_size=out_window_size,\n",
    "                         input_transform=input_transform,\n",
    "                         output_transform=output_transform,\n",
    "                         fillval=fill_value)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, \n",
    "                      shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324ff733-98ca-49da-9cfd-896660bdad03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5474661404044111), np.float64(0.6561926480601338))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds._data.mean(), train_ds._data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442ce60b-1ee4-43b6-a7d8-bfaf98b41083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1336, 40, 40, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acc24a-89a4-4b41-bccf-dfa41e11b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73325cef-f56a-4996-bcf9-36ef4714ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb368b6-171f-41f4-a0c9-4b2589abc315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a174c165-2881-46b9-bbe5-01fc155fd504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = GWGridDataset(data_path=interpolated_data_dir,\n",
    "                         dataset='val', val_ratio=val_ratio,\n",
    "                         in_window_size=in_window_size,\n",
    "                         out_window_size=out_window_size,\n",
    "                         input_transform=input_transform,\n",
    "                         output_transform=output_transform,\n",
    "                         fillval=fill_value)\n",
    "\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, \n",
    "                      shuffle=False, pin_memory=True)\n",
    "\n",
    "len(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdb335c-9e3a-4a12-944d-82b76867e308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds._data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428716df-ca14-4e57-9403-98458d35ac8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds._data.shape[0] + train_ds._data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef828e60-8e2d-4c65-897e-1d6468603a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600affb8-f48c-4d9b-955c-ad1491f03451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4d861-62a3-4f25-8473-5ab5b7aa3ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5f724-93ab-4c7a-a4ab-7ac33b4e5990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62d4a3a-187d-41ca-9b81-22636a8ed6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found following device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Found following device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb730a6c-a2c4-49a1-b069-6df17586a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2loss = LpLoss(d=3, p=2)\n",
    "# h1loss = H1Loss(d=3)\n",
    "\n",
    "# train_loss = h1loss\n",
    "# eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "\n",
    "# Model configuration\n",
    "n_modes = (16, 16, 16)\n",
    "in_channels = in_window_size\n",
    "out_channels = out_window_size\n",
    "hidden_channels = 64\n",
    "projection_channels = 64\n",
    "# scheduler_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df3a22a-bf1d-4742-ba40-4355502117dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO(n_modes=n_modes, in_channels=in_channels, \n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=hidden_channels, \n",
    "            projection_channels=projection_channels).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f3c7d8-3a15-4a3c-99bf-4a9fa54a3d87",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FNO:\n\tMissing key(s) in state_dict: \"fno_blocks.fno_skips.0.weight\", \"fno_blocks.fno_skips.1.weight\", \"fno_blocks.fno_skips.2.weight\", \"fno_blocks.fno_skips.3.weight\", \"fno_blocks.convs.0.bias\", \"fno_blocks.convs.0.weight.0.tensor\", \"fno_blocks.convs.1.bias\", \"fno_blocks.convs.1.weight.0.tensor\", \"fno_blocks.convs.2.bias\", \"fno_blocks.convs.2.weight.0.tensor\", \"fno_blocks.convs.3.bias\", \"fno_blocks.convs.3.weight.0.tensor\". \n\tUnexpected key(s) in state_dict: \"convs.bias\", \"convs.weight.0.tensor\", \"convs.weight.1.tensor\", \"convs.weight.2.tensor\", \"convs.weight.3.tensor\", \"fno_skips.0.weight\", \"fno_skips.1.weight\", \"fno_skips.2.weight\", \"fno_skips.3.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m results_path = \u001b[33m'\u001b[39m\u001b[33m/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/01_PhD/05_groundwater/results/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m model_path = os.path.join(results_path, \u001b[33m'\u001b[39m\u001b[33msavedmodel_fno\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralop-env/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for FNO:\n\tMissing key(s) in state_dict: \"fno_blocks.fno_skips.0.weight\", \"fno_blocks.fno_skips.1.weight\", \"fno_blocks.fno_skips.2.weight\", \"fno_blocks.fno_skips.3.weight\", \"fno_blocks.convs.0.bias\", \"fno_blocks.convs.0.weight.0.tensor\", \"fno_blocks.convs.1.bias\", \"fno_blocks.convs.1.weight.0.tensor\", \"fno_blocks.convs.2.bias\", \"fno_blocks.convs.2.weight.0.tensor\", \"fno_blocks.convs.3.bias\", \"fno_blocks.convs.3.weight.0.tensor\". \n\tUnexpected key(s) in state_dict: \"convs.bias\", \"convs.weight.0.tensor\", \"convs.weight.1.tensor\", \"convs.weight.2.tensor\", \"convs.weight.3.tensor\", \"fno_skips.0.weight\", \"fno_skips.1.weight\", \"fno_skips.2.weight\", \"fno_skips.3.weight\". "
     ]
    }
   ],
   "source": [
    "results_path = '/srv/scratch/z5370003/projects/04_groundwater/variable_density/results/FNO/20250529_184905'\n",
    "results_path = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/01_PhD/05_groundwater/results/'\n",
    "model_path = os.path.join(results_path, 'savedmodel_fno')\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbabb7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/01_PhD/05_groundwater/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9556aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773d0c9c-393e-4be9-97de-22457133c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:07<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "model_handler = ModelHandler(model=model, device=device)\n",
    "\n",
    "# Generate predictions\n",
    "preds = np.array(model_handler.predict(val_dl))\n",
    "preds = output_transform.inverse_transform(preds)\n",
    "\n",
    "# Get targets\n",
    "targets = model_handler.get_targets(val_dl)\n",
    "targets = output_transform.inverse_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc37765-1e4e-48e0-9e2a-bad7eb53e67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501292ec-c4d3-4883-96af-b9811e37f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03de2340-5c2d-4e14-99bb-0c47b931ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 256, 40, 40, 40]           1,536\n",
      "            Conv3d-2       [-1, 64, 40, 40, 40]          16,448\n",
      "               MLP-3       [-1, 64, 40, 40, 40]               0\n",
      "            Conv3d-4       [-1, 64, 40, 40, 40]           4,096\n",
      "      SpectralConv-5       [-1, 64, 40, 40, 40]             256\n",
      "            Conv3d-6       [-1, 64, 40, 40, 40]           4,096\n",
      "      SpectralConv-7       [-1, 64, 40, 40, 40]             256\n",
      "            Conv3d-8       [-1, 64, 40, 40, 40]           4,096\n",
      "      SpectralConv-9       [-1, 64, 40, 40, 40]             256\n",
      "           Conv3d-10       [-1, 64, 40, 40, 40]           4,096\n",
      "     SpectralConv-11       [-1, 64, 40, 40, 40]             256\n",
      "           Conv3d-12       [-1, 64, 40, 40, 40]           4,160\n",
      "           Conv3d-13        [-1, 5, 40, 40, 40]             325\n",
      "              MLP-14        [-1, 5, 40, 40, 40]               0\n",
      "================================================================\n",
      "Total params: 39,877\n",
      "Trainable params: 38,853\n",
      "Non-trainable params: 1,024\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.22\n",
      "Forward/backward pass size (MB): 473.63\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 475.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.float(), val_ds[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80ee65-e552-41de-bdf5-28cc3dbddf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f950774-0bf2-415f-8332-9b346127b24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75fd50-307f-414b-96af-c3e4338d8d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b761861-c16d-4f9c-8796-72d641036016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e8ed9-68d3-49c9-ae82-d366f8106cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "362e9235-7c8b-43bd-a23f-137d04d81ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[targets == fill_value] = np.nan\n",
    "targets[targets == fill_value] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1baecb2-4a7d-4106-8bce-b2c1f9bb09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_projection(x_grid, y_grid, z_grid, values, vmin=None, vmax=None, title=None, cmap='viridis'):\n",
    "\n",
    "    # Create a figure with 3 subplots for different slices\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # If vmin or vmax is not provided, use the min and max of the values\n",
    "    if vmin is None:\n",
    "        vmin = np.nanmin(values)\n",
    "    if vmax is None:\n",
    "        vmax = np.nanmax(values)\n",
    "\n",
    "    \n",
    "    # YZ plane (constant X)\n",
    "    for ix in range(values.shape[0]):\n",
    "        im1 = ax1.imshow(values[ix,:,:].T, aspect='auto', \n",
    "                        extent=[y_grid[0], y_grid[-1], z_grid[0], z_grid[-1]],\n",
    "                        origin='lower', cmap=cmap, alpha=0.1, vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title('YZ plane (constant X)')\n",
    "    ax1.set_xlabel('Y')\n",
    "    ax1.set_ylabel('Z')\n",
    "    plt.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # XZ plane (constant Y)\n",
    "    for iy in range(values.shape[1]):\n",
    "        im2 = ax2.imshow(values[:,iy,:].T, aspect='auto',\n",
    "                        extent=[x_grid[0], x_grid[-1], z_grid[0], z_grid[-1]],\n",
    "                        origin='lower', cmap=cmap, alpha=0.1, vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title('XZ plane (constant Y)')\n",
    "    ax2.set_xlabel('X')\n",
    "    ax2.set_ylabel('Z')\n",
    "    plt.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    # XY plane (constant Z)\n",
    "    for iz in range(values.shape[2]):\n",
    "        im3 = ax3.imshow(values[:,:,iz].T, aspect='auto',\n",
    "                        extent=[x_grid[0], x_grid[-1], y_grid[0], y_grid[-1]],\n",
    "                        origin='lower', cmap=cmap, alpha=0.1, vmin=vmin, vmax=vmax)\n",
    "    ax3.set_title('XY plane (constant Z)')\n",
    "    ax3.set_xlabel('X')\n",
    "    ax3.set_ylabel('Y')\n",
    "    plt.colorbar(im3, ax=ax3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55e85a3f-ebd5-497b-af05-b7555f4a78b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preds[np.isclose(preds, -1, atol=5e-3)] = -1\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59d198de-4902-45a1-af8c-7a91f728a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_path = os.path.join(results_path, 'targets')\n",
    "preds_path = os.path.join(results_path, 'preds')\n",
    "\n",
    "os.makedirs(targets_path, exist_ok=True)\n",
    "os.makedirs(preds_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e534c4c6-d656-473e-aad6-f312ad465020",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_path = os.path.join(results_path, 'errors')\n",
    "os.makedirs(errors_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd05ff-2373-44c1-bab9-8978494b8ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25227bda-0e2f-48b0-8aaa-35accbe4c170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cec52820-38eb-4437-9968-cdd5ffaed88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [31:18<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "vmin = np.nanmin(targets)\n",
    "vmax = np.nanmax(targets)\n",
    "\n",
    "max_error = np.nanmax(np.abs(preds[:, 0] - targets[:, 0]))\n",
    "\n",
    "\n",
    "for t in trange(targets.shape[0]):\n",
    "\n",
    "    # Plot targets\n",
    "    target_fig = plot_2d_projection(val_ds.x_grid, val_ds.y_grid, val_ds.z_grid, \n",
    "                    targets[t, 0], vmin=vmin, vmax=vmax, title='Targets')\n",
    "    target_fig.savefig(os.path.join(targets_path, f'{str(t).zfill(4)}.png'))\n",
    "    plt.close(target_fig)\n",
    "\n",
    "\n",
    "    # Plot predictions\n",
    "    pred_fig = plot_2d_projection(val_ds.x_grid, val_ds.y_grid, val_ds.z_grid, \n",
    "                    preds[t, 0], vmin=vmin, vmax=vmax, title='Predictions')\n",
    "    \n",
    "    pred_fig.savefig(os.path.join(preds_path, f'{str(t).zfill(4)}.png'))\n",
    "    plt.close(pred_fig)\n",
    "\n",
    "\n",
    "    # Plot errors\n",
    "    error_fig = plot_2d_projection(val_ds.x_grid, val_ds.y_grid, val_ds.z_grid, \n",
    "                                   preds[t, 0] - targets[t, 0], title='Error (Preds - Targets)', \n",
    "                                   vmin=-max_error, vmax=max_error, cmap='coolwarm')\n",
    "    error_fig.savefig(os.path.join(errors_path, f'{str(t).zfill(4)}.png'))\n",
    "    plt.close(error_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbdd1842-eda2-41c5-96b7-70555e3c66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16ce58c8-8fde-4ed7-9669-8574775f54d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:18<00:00, 29.78it/s]\n"
     ]
    }
   ],
   "source": [
    "video_name = os.path.join(results_path, 'hydraulic_head_error.avi')\n",
    "\n",
    "frames = [f for f in sorted(os.listdir(targets_path)) if not f.startswith('.')]\n",
    "\n",
    "# Configure frame paths\n",
    "target_frame_path = os.path.join(targets_path, frames[0])\n",
    "pred_frame_path = os.path.join(preds_path, frames[0])\n",
    "error_frame_path = os.path.join(errors_path, frames[0])\n",
    "\n",
    "# Read frames from file\n",
    "target_frame = cv2.imread(target_frame_path)\n",
    "pred_frame = cv2.imread(pred_frame_path)\n",
    "error_frame = cv2.imread(error_frame_path)\n",
    "\n",
    "# vertically concatenate images\n",
    "combined_frame = cv2.vconcat([target_frame, pred_frame, error_frame])\n",
    "\n",
    "# Configure video writer\n",
    "height, width, layers = combined_frame.shape\n",
    "video = cv2.VideoWriter(video_name, 0, 4, (width//2, height//2))\n",
    "\n",
    "\n",
    "for frame in tqdm(frames):\n",
    "    \n",
    "    # Configure frame paths\n",
    "    target_frame_path = os.path.join(targets_path, frame)\n",
    "    pred_frame_path = os.path.join(preds_path, frame)\n",
    "    error_frame_path = os.path.join(errors_path, frame)\n",
    "    \n",
    "    # Read frames from file\n",
    "    target_frame = cv2.imread(target_frame_path)\n",
    "    pred_frame = cv2.imread(pred_frame_path)\n",
    "    error_frame = cv2.imread(error_frame_path)\n",
    "    \n",
    "    # vertically concatenate images\n",
    "    combined_frame = cv2.vconcat([target_frame, pred_frame, error_frame])\n",
    "    combined_frame = cv2.resize(combined_frame, (width//2, height//2))\n",
    "\n",
    "    # Write to file\n",
    "    video.write(combined_frame)\n",
    "\n",
    "# Cleanup\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b7555-d229-47b2-871a-5ba5c6523f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c39bd-6155-4ded-8400-09fc3ea4496d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37c6fd-e448-4b95-96ac-0e0278f8f2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
