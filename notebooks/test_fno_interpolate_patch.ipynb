{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6639a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.neuralop.fno import FNOInterpolate\n",
    "from src.data.patch_dataset_multi_col import GWPatchDatasetMultiCol\n",
    "from src.data.batch_sampler import PatchBatchSampler\n",
    "from src.data.data_utils import (\n",
    "    calculate_coord_transform,\n",
    "    calculate_obs_transform,\n",
    "    create_patch_datasets,\n",
    "    make_collate_fn,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c7908b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d037622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Target columns: ['mass_concentration', 'head']\n",
      "Input/Output channels: 6/2\n",
      "Latent grid size: (32, 32, 24)\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data configuration\n",
    "base_data_dir = '/srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density'\n",
    "raw_data_dir = f'{base_data_dir}/all'\n",
    "patch_data_dir = f'{base_data_dir}/filter_patch'\n",
    "\n",
    "# Dataset parameters\n",
    "target_cols = ['mass_concentration', 'head']\n",
    "target_col_indices = [0, 1]  # Corresponding to mass_concentration and head\n",
    "input_window_size = 3\n",
    "output_window_size = 1\n",
    "batch_size = 2\n",
    "\n",
    "# Model hyperparameters (matching GINO training config)\n",
    "coord_dim = 3\n",
    "latent_grid_size = (32, 32, 24)  # Matching latent_query_dims from GINO training\n",
    "n_target_cols = len(target_cols)\n",
    "in_channels = input_window_size * n_target_cols  # 3 * 2 = 6\n",
    "out_channels = output_window_size * n_target_cols  # 1 * 2 = 2\n",
    "latent_feature_channels = None\n",
    "fno_hidden_channels = 64\n",
    "fno_n_layers = 4\n",
    "fno_n_modes = (12, 12, 8)\n",
    "lifting_channels = 64\n",
    "\n",
    "print(f\"Target columns: {target_cols}\")\n",
    "print(f\"Input/Output channels: {in_channels}/{out_channels}\")\n",
    "print(f\"Latent grid size: {latent_grid_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b2f71",
   "metadata": {},
   "source": [
    "## Load Patch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4eafe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coordinate transform...\n",
      "Coordinate mean: [ 3.57225665e+05  6.45774324e+06 -9.27782248e+00]\n",
      "Coordinate std: [569.1699999  566.35797379  15.26565618]\n",
      "Calculating observation transform...\n",
      "Output mean: [1.77942252e+04 3.95881156e-01 9.48469883e+01]\n",
      "Output std: [1.55859465e+04 2.13080032e-01 1.51226320e+02]\n",
      "Creating datasets...\n",
      "Computed variance-aware weights for 20 patches\n",
      "Dataset variance range: [0.000000, 405223819.275790]\n",
      "Dataset mean variance: 3213522.908705\n",
      "Weight range: [0.4446, 3.4922]\n",
      "Weight std: 0.2615\n",
      "Computed variance-aware weights for 20 patches\n",
      "Dataset variance range: [0.000000, 405223819.275790]\n",
      "Dataset mean variance: 3213522.908705\n",
      "Weight range: [0.4446, 3.4922]\n",
      "Weight std: 0.2615\n",
      "Dataset sizes - Train: 13300, Val: 5680\n"
     ]
    }
   ],
   "source": [
    "# Calculate data transforms\n",
    "print(\"Calculating coordinate transform...\")\n",
    "coord_transform = calculate_coord_transform(raw_data_dir)\n",
    "\n",
    "print(\"Calculating observation transform...\")\n",
    "obs_transform = calculate_obs_transform(\n",
    "    raw_data_dir,\n",
    "    target_obs_cols=['mass_concentration', 'head', 'pressure']\n",
    ")\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_ds, val_ds = create_patch_datasets(\n",
    "    dataset_class=GWPatchDatasetMultiCol,\n",
    "    patch_data_dir=patch_data_dir,\n",
    "    coord_transform=coord_transform,\n",
    "    obs_transform=obs_transform,\n",
    "    target_col_indices=target_col_indices,\n",
    "    input_window_size=input_window_size,\n",
    "    output_window_size=output_window_size,\n",
    ")\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_ds)}, Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415f0b8",
   "metadata": {},
   "source": [
    "## Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81fc046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building patch groups (one-time operation)...\n",
      "Building patch_ids cache...\n",
      "Cached 5680 patch_ids\n",
      "Found 20 patches with 5680 total samples\n",
      "Patch sizes: min=284, max=284, avg=284.0\n",
      "Pre-built 2840 batches\n",
      "Data loader created with 2840 batches\n",
      "Getting first batch...\n"
     ]
    }
   ],
   "source": [
    "# Create batch sampler and data loader\n",
    "val_sampler = PatchBatchSampler(\n",
    "    val_ds, \n",
    "    batch_size=batch_size,\n",
    "    shuffle_within_batches=False,\n",
    "    shuffle_patches=False,\n",
    "    seed=None\n",
    ")\n",
    "\n",
    "# Create collate function (simplified args)\n",
    "class SimpleArgs:\n",
    "    def __init__(self):\n",
    "        self.input_window_size = input_window_size\n",
    "        self.output_window_size = output_window_size\n",
    "        self.latent_query_dims = latent_grid_size\n",
    "        self.use_open3d = False\n",
    "        self.device = device\n",
    "\n",
    "args = SimpleArgs()\n",
    "collate_fn = make_collate_fn(args, coord_dim=coord_dim)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_sampler=val_sampler, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Data loader created with {len(val_loader)} batches\")\n",
    "print(\"Getting first batch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56820c24",
   "metadata": {},
   "source": [
    "## Initialize FNOInterpolate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3ad4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "Total parameters: 23,631,362\n"
     ]
    }
   ],
   "source": [
    "model = FNOInterpolate(\n",
    "    latent_grid_size=latent_grid_size,\n",
    "    coord_dim=coord_dim,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    latent_feature_channels=latent_feature_channels,\n",
    "    fno_n_layers=fno_n_layers,\n",
    "    fno_n_modes=fno_n_modes,\n",
    "    fno_hidden_channels=fno_hidden_channels,\n",
    "    lifting_channels=lifting_channels,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model initialized on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd046b",
   "metadata": {},
   "source": [
    "## Extract and Inspect Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9882cea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available batch keys:\n",
      "dict_keys(['point_coords', 'latent_queries', 'x', 'y', 'core_len', 'weights'])\n",
      "\n",
      "Batch data shapes:\n",
      "  input_geom: torch.Size([512, 3])\n",
      "  latent_queries: torch.Size([32, 32, 24, 3])\n",
      "  x_input: torch.Size([2, 512, 6])\n",
      "  y_target: torch.Size([2, 512, 2])\n",
      "  latent_features: None\n",
      "  output_queries: torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get first batch from validation loader\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "# First, inspect what keys are in the batch\n",
    "print(\"Available batch keys:\")\n",
    "print(batch.keys())\n",
    "print()\n",
    "\n",
    "# Extract batch components (using tensors, not dictionaries)\n",
    "input_geom = batch['point_coords'].to(device)\n",
    "latent_queries = batch['latent_queries'].to(device)\n",
    "output_queries = batch['point_coords'].to(device)  # Use same points as input for testing\n",
    "x_input = batch['x'].to(device)\n",
    "y_target = batch['y'].to(device)\n",
    "latent_features = batch.get('latent_features')\n",
    "if latent_features is not None:\n",
    "    latent_features = latent_features.to(device)\n",
    "\n",
    "print(\"Batch data shapes:\")\n",
    "print(f\"  input_geom: {input_geom.shape}\")\n",
    "print(f\"  latent_queries: {latent_queries.shape}\")\n",
    "print(f\"  x_input: {x_input.shape}\")\n",
    "print(f\"  y_target: {y_target.shape}\")\n",
    "print(f\"  latent_features: {latent_features.shape if latent_features is not None else None}\")\n",
    "print(f\"  output_queries: {output_queries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24a3a0",
   "metadata": {},
   "source": [
    "## Forward Pass Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635914fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass...\n",
      "\n",
      "Forward pass successful!\n",
      "Prediction output shape: torch.Size([2, 512, 2])\n",
      "Target output shape: torch.Size([2, 512, 2])\n",
      "\n",
      "Shapes match: ✓\n",
      "\n",
      "Both tensors have shape: (batch_size=2, n_points=512, channels=2)\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass through FNOInterpolate model\n",
    "print(\"Running forward pass...\")\n",
    "with torch.no_grad():\n",
    "    y_pred = model(\n",
    "        input_geom=input_geom,\n",
    "        latent_queries=latent_queries,\n",
    "        output_queries=output_queries,\n",
    "        x=x_input,\n",
    "        latent_features=latent_features\n",
    "    )\n",
    "\n",
    "print(f\"\\nForward pass successful!\")\n",
    "print(f\"Prediction output shape: {y_pred.shape}\")\n",
    "print(f\"Target output shape: {y_target.shape}\")\n",
    "\n",
    "# Verify shapes match\n",
    "shapes_match = y_pred.shape == y_target.shape\n",
    "print(f\"\\n{'Shapes match: ✓' if shapes_match else 'Shapes match: ✗'}\")\n",
    "\n",
    "if shapes_match:\n",
    "    print(f\"\\nBoth tensors have shape: (batch_size={y_pred.shape[0]}, n_points={y_pred.shape[1]}, channels={y_pred.shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b4aaa",
   "metadata": {},
   "source": [
    "## Prediction Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd999411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: torch.Size([2, 512, 2])\n",
      "  Batch size: 2\n",
      "  Num points: 512\n",
      "  Output channels: 2 (expected 2)\n",
      "\n",
      "Prediction statistics:\n",
      "  Mean: 0.004121\n",
      "  Std: 0.014030\n",
      "  Min: -0.016462\n",
      "  Max: 0.037722\n",
      "\n",
      "Target statistics:\n",
      "  Mean: -0.169145\n",
      "  Std: 0.824083\n",
      "  Min: -2.297711\n",
      "  Max: 1.786044\n",
      "\n",
      "MSE Loss: 0.698116\n"
     ]
    }
   ],
   "source": [
    "# Analyze predictions and targets\n",
    "print(f\"Prediction shape: {y_pred.shape}\")\n",
    "print(f\"  Batch size: {y_pred.shape[0]}\")\n",
    "print(f\"  Num points: {y_pred.shape[1]}\")\n",
    "print(f\"  Output channels: {y_pred.shape[2]} (expected {out_channels})\")\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Mean: {y_pred.mean().item():.6f}\")\n",
    "print(f\"  Std: {y_pred.std().item():.6f}\")\n",
    "print(f\"  Min: {y_pred.min().item():.6f}\")\n",
    "print(f\"  Max: {y_pred.max().item():.6f}\")\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Mean: {y_target.mean().item():.6f}\")\n",
    "print(f\"  Std: {y_target.std().item():.6f}\")\n",
    "print(f\"  Min: {y_target.min().item():.6f}\")\n",
    "print(f\"  Max: {y_target.max().item():.6f}\")\n",
    "\n",
    "# Calculate MSE loss\n",
    "mse = torch.nn.functional.mse_loss(y_pred, y_target)\n",
    "print(f\"\\nMSE Loss: {mse.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449ef2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Successfully tested FNOInterpolate model with patch dataset! The model:\n",
    "- ✓ Loaded real patch dataset with multi-column support\n",
    "- ✓ Processed batch through forward pass\n",
    "- ✓ Generated predictions matching target shapes\n",
    "- ✓ Maintained API compatibility with GINO training pipeline\n",
    "- ✓ Works with dictionary-based patch outputs\n",
    "\n",
    "The FNOInterpolate model is ready for training on the groundwater dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bab24e-1b77-4ba1-ad54-8a0dc2a605a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (torch-env)",
   "language": "python",
   "name": "conda_torch-env_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
