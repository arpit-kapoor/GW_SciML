{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1988ab4",
   "metadata": {},
   "source": [
    "# Generate 2D Plane Sequence Data\n",
    "\n",
    "This notebook reads raw 2D plane data from FEFLOW simulations and generates temporal sequences for training the GFNO model.\n",
    "\n",
    "**Output**: Saves sequence data organized by planes to disk for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d761332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828cedfa",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11240856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data paths\n",
    "data_path = '/Users/arpitkapoor/data/GW/2d_plane_data'\n",
    "sea_level_csv = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Data/FEFLOW/simulation_files/SeaLevelDataPeaksHL.csv'\n",
    "\n",
    "# Output data path\n",
    "output_data_dir = '/Users/arpitkapoor/data/GW/2d_plane_sequences'\n",
    "\n",
    "# Processing parameters\n",
    "skip_factor = 2  # Process every 2nd timestep for faster processing\n",
    "alpha = 16  # Sequence length for input and output\n",
    "N_planes = 32  # Number of planes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac5a15",
   "metadata": {},
   "source": [
    "## Load Timestep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59467af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 955 timesteps\n",
      "Found 955 timestep directories\n"
     ]
    }
   ],
   "source": [
    "# Load time data\n",
    "times = pd.read_csv(sea_level_csv, header=None, names=['time', 'sealevel'])['time'].values[::skip_factor]\n",
    "print(f\"Loaded {len(times)} timesteps\")\n",
    "\n",
    "# Get sorted data directories\n",
    "sorted_data_dirs = sorted(os.listdir(data_path))\n",
    "sorted_data_dirs = [d for d in sorted_data_dirs if d.startswith('timestep_')]\n",
    "sorted_data_dirs = sorted_data_dirs[::skip_factor]\n",
    "print(f\"Found {len(sorted_data_dirs)} timestep directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee2269",
   "metadata": {},
   "source": [
    "## Load and Process Plane Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438289f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading plane data across all timesteps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 955/955 [00:18<00:00, 52.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loading complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize storage for all planes\n",
    "plane_data_all_timesteps = {p: [] for p in range(N_planes)}\n",
    "bc_data_all_timesteps = {p: [] for p in range(N_planes)}\n",
    "bc_nodes_for_plane = {}\n",
    "\n",
    "print(\"Loading plane data across all timesteps...\")\n",
    "for t in tqdm(range(len(sorted_data_dirs))):\n",
    "    d = sorted_data_dirs[t]\n",
    "    ts_dir = os.path.join(data_path, d)\n",
    "    sorted_planes_dir = sorted(os.listdir(ts_dir))\n",
    "    sorted_planes_dir = [os.path.join(ts_dir, f) for f in sorted_planes_dir]\n",
    "\n",
    "    for p, f in enumerate(sorted_planes_dir):\n",
    "        # Load plane data\n",
    "        plane_data = np.load(os.path.join(f, 'plane_data.npz'))\n",
    "        S = plane_data['S']\n",
    "        Z = plane_data['Z']\n",
    "        X = plane_data['X']\n",
    "        Y = plane_data['Y']\n",
    "        T = np.ones_like(X) * times[t]\n",
    "        head_m = plane_data['head_m']\n",
    "        mass_conc_mg_l = plane_data['mass_conc_mg_l']\n",
    "        \n",
    "        # Stack: S, Z, T, X, Y, head, mass_conc\n",
    "        stacked_plane = np.stack([T, S, Z, X, Y, head_m, mass_conc_mg_l], axis=-1)\n",
    "        plane_data_all_timesteps[p].append(stacked_plane)\n",
    "\n",
    "        # Load boundary condition data\n",
    "        bc_data = np.load(os.path.join(f, 'bc_data.npz'))\n",
    "        bc_node_idx = bc_data['node_idx']\n",
    "        bc_S = bc_data['S']\n",
    "        bc_Z = bc_data['Z']\n",
    "        bc_T = np.ones_like(bc_node_idx) * times[t]\n",
    "        bc_head = bc_data['head']\n",
    "        bc_mass_conc = bc_data['mass_conc']\n",
    "        \n",
    "        # Validate BC data consistency\n",
    "        if not len(bc_S) == len(bc_Z) == len(bc_head) == len(bc_mass_conc):\n",
    "            print(f\"Warning: Plane {p} at timestep {t} has mismatched BC array lengths\")\n",
    "            continue\n",
    "\n",
    "        # Track consistent BC nodes across timesteps\n",
    "        if t == 0:\n",
    "            bc_nodes_for_plane[p] = bc_node_idx.astype(np.int32)\n",
    "        else:\n",
    "            bc_nodes_for_plane[p] = np.intersect1d(bc_nodes_for_plane[p], bc_node_idx.astype(np.int32))\n",
    "\n",
    "        # Stack BC data: node_idx, S, Z, T, head, mass_conc\n",
    "        stacked_bc = np.stack([bc_node_idx, bc_T, bc_S, bc_Z, bc_head, bc_mass_conc], axis=-1)\n",
    "        bc_data_all_timesteps[p].append(stacked_bc)\n",
    "\n",
    "print(\"\\nData loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c9ba8",
   "metadata": {},
   "source": [
    "## Stack Data Across Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18876761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking plane data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 76.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example plane data shape: (955, 32, 32, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Stack plane data\n",
    "print(\"Stacking plane data...\")\n",
    "for p in tqdm(range(N_planes)):\n",
    "    plane_data_p = plane_data_all_timesteps[p]\n",
    "    plane_data_all_timesteps[p] = np.stack(plane_data_p, axis=0)\n",
    "\n",
    "print(f\"Example plane data shape: {plane_data_all_timesteps[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84509a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning and stacking BC data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 69.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example BC data shape: (955, 326, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and stack BC data (filter to consistent nodes only)\n",
    "print(\"\\nCleaning and stacking BC data...\")\n",
    "for p in tqdm(range(N_planes)):\n",
    "    bc_list = bc_data_all_timesteps[p]\n",
    "    n_bc = len(bc_list)\n",
    "    bc_data_for_selected_nodes = []\n",
    "\n",
    "    for t in range(n_bc):\n",
    "        bc_data_for_p_at_t = bc_data_all_timesteps[p][t]\n",
    "        bc_nodes_for_p = bc_nodes_for_plane[p]\n",
    "        \n",
    "        # Filter to only consistent BC nodes\n",
    "        mask = np.isin(bc_data_for_p_at_t[:, 0], bc_nodes_for_p)\n",
    "        bc_data_for_selected_nodes.append(bc_data_for_p_at_t[mask])\n",
    "    \n",
    "    bc_data_all_timesteps[p] = np.stack(bc_data_for_selected_nodes, axis=0)\n",
    "\n",
    "print(f\"Example BC data shape: {bc_data_all_timesteps[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3037e51d",
   "metadata": {},
   "source": [
    "## Generate Temporal Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1160909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 116 time sequences with alpha=16\n",
      "First sequence: (0, 16, 32) -> times: [ 0.         13.91666667 26.91666667]\n",
      "Last sequence: (920, 936, 952) -> times: [875.5833333 891.4583333 906.3333333]\n"
     ]
    }
   ],
   "source": [
    "# Initialize sequence storage\n",
    "input_sequences = {p: {'input_geom': [], 'input_data': [], 'latent_geom': [], 'latent_features': []} for p in range(N_planes)}\n",
    "output_sequences = {p: {'latent_geom': [], 'latent_features': []} for p in range(N_planes)}\n",
    "\n",
    "# Generate time sequence indices\n",
    "n_timesteps = len(sorted_data_dirs)\n",
    "ts = [(i, i + alpha, i + 2 * alpha) for i in range(0, n_timesteps - 2 * alpha + 1, alpha//2)]\n",
    "\n",
    "print(f\"Generated {len(ts)} time sequences with alpha={alpha}\")\n",
    "print(f\"First sequence: {ts[0]} -> times: {times[list(ts[0])]}\")\n",
    "print(f\"Last sequence: {ts[-1]} -> times: {times[list(ts[-1])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e30a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating sequences for all planes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 3648.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence generation complete!\n",
      "Total sequences per plane: 116\n",
      "Total planes: 32\n",
      "\n",
      "Example shapes for plane 0:\n",
      "  input_geom: (116, 5216, 3)\n",
      "  input_data: (116, 5216, 2)\n",
      "  latent_geom: (116, 16, 32, 32, 3)\n",
      "  latent_features: (116, 16, 32, 32, 7)\n",
      "  output_latent_geom: (116, 16, 32, 32, 3)\n",
      "  output_latent_features: (116, 16, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences for all planes\n",
    "print(\"\\nGenerating sequences for all planes...\")\n",
    "for p in tqdm(range(N_planes)):\n",
    "    bc_data = bc_data_all_timesteps[p]  # (n_timesteps, n_bc_nodes, 6)\n",
    "    plane_data = plane_data_all_timesteps[p]  # (n_timesteps, n_nodes, 7)\n",
    "    \n",
    "    for t_start, t_mid, t_end in ts:\n",
    "        # Input sequence: [t_start:t_mid]\n",
    "        input_geom_seq = bc_data[t_start:t_mid, ..., 1:4].reshape(-1, 3)  # T, S, Z\n",
    "        input_data_seq = bc_data[t_start:t_mid, ..., 4:].reshape(-1, 2)  # head, mass_conc\n",
    "        \n",
    "        latent_geom_seq = plane_data[t_start:t_mid, ..., :3]  # T, S, Z\n",
    "        latent_features_seq = plane_data[t_start:t_mid, ..., :]  # T, S, Z X, Y, head, mass_conc\n",
    "        \n",
    "        # Output sequence: [t_mid:t_end]\n",
    "        output_latent_geom_seq = plane_data[t_mid:t_end, ..., :3]\n",
    "        output_latent_features_seq = plane_data[t_mid:t_end, ..., -2:]\n",
    "        \n",
    "        # Store sequences\n",
    "        input_sequences[p]['input_geom'].append(input_geom_seq)\n",
    "        input_sequences[p]['input_data'].append(input_data_seq)\n",
    "        input_sequences[p]['latent_geom'].append(latent_geom_seq)\n",
    "        input_sequences[p]['latent_features'].append(latent_features_seq)\n",
    "        \n",
    "        output_sequences[p]['latent_geom'].append(output_latent_geom_seq)\n",
    "        output_sequences[p]['latent_features'].append(output_latent_features_seq)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "for p in range(N_planes):\n",
    "    for key in input_sequences[p]:\n",
    "        input_sequences[p][key] = np.array(input_sequences[p][key])\n",
    "    for key in output_sequences[p]:\n",
    "        output_sequences[p][key] = np.array(output_sequences[p][key])\n",
    "\n",
    "print(f\"\\nSequence generation complete!\")\n",
    "print(f\"Total sequences per plane: {len(ts)}\")\n",
    "print(f\"Total planes: {N_planes}\")\n",
    "print(f\"\\nExample shapes for plane 0:\")\n",
    "print(f\"  input_geom: {input_sequences[0]['input_geom'].shape}\")\n",
    "print(f\"  input_data: {input_sequences[0]['input_data'].shape}\")\n",
    "print(f\"  latent_geom: {input_sequences[0]['latent_geom'].shape}\")\n",
    "print(f\"  latent_features: {input_sequences[0]['latent_features'].shape}\")\n",
    "print(f\"  output_latent_geom: {output_sequences[0]['latent_geom'].shape}\")\n",
    "print(f\"  output_latent_features: {output_sequences[0]['latent_features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d28df7",
   "metadata": {},
   "source": [
    "## Save Sequences to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5646b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plane sequence data to /Users/arpitkapoor/data/GW/2d_plane_sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:08<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved successfully!\n",
      "Output directory: /Users/arpitkapoor/data/GW/2d_plane_sequences\n",
      "Configuration saved to: /Users/arpitkapoor/data/GW/2d_plane_sequences/config.json\n",
      "\n",
      "You can now use this data with GWPlaneDatasetFromFiles in the model training notebook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving plane sequence data to {output_data_dir}...\")\n",
    "\n",
    "for p in tqdm(range(N_planes)):\n",
    "    plane_dir = os.path.join(output_data_dir, f'plane_{p:02d}')\n",
    "    os.makedirs(plane_dir, exist_ok=True)\n",
    "    \n",
    "    # Save all sequence data for this plane\n",
    "    np.save(os.path.join(plane_dir, 'input_geom.npy'), input_sequences[p]['input_geom'])\n",
    "    np.save(os.path.join(plane_dir, 'input_data.npy'), input_sequences[p]['input_data'])\n",
    "    np.save(os.path.join(plane_dir, 'latent_geom.npy'), input_sequences[p]['latent_geom'])\n",
    "    np.save(os.path.join(plane_dir, 'latent_features.npy'), input_sequences[p]['latent_features'])\n",
    "    np.save(os.path.join(plane_dir, 'output_latent_geom.npy'), output_sequences[p]['latent_geom'])\n",
    "    np.save(os.path.join(plane_dir, 'output_latent_features.npy'), output_sequences[p]['latent_features'])\n",
    "\n",
    "# Save configuration metadata\n",
    "\n",
    "config = {\n",
    "    \"n_planes\": N_planes,\n",
    "    \"n_sequences_per_plane\": len(ts),\n",
    "    \"sequence_length\": alpha,\n",
    "    \"skip_factor\": skip_factor,\n",
    "    \"n_timesteps\": n_timesteps,\n",
    "    \"data_path\": data_path,\n",
    "    \"sea_level_csv\": sea_level_csv\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_data_dir, 'config.json'), 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"\\nData saved successfully!\")\n",
    "print(f\"Output directory: {output_data_dir}\")\n",
    "print(f\"Configuration saved to: {os.path.join(output_data_dir, 'config.json')}\")\n",
    "print(f\"\\nYou can now use this data with GWPlaneDatasetFromFiles in the model training notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31301aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
