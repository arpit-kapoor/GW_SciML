{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62ed114",
   "metadata": {},
   "source": [
    "# Test GFNO Model on 2D Plane Sequences\n",
    "\n",
    "This notebook loads pre-generated sequence data and tests the GFNO model with proper dataset, sampler, and dataloader setup.\n",
    "\n",
    "**CUDA Compatible**: Automatically detects and uses GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9b3794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add project root to path\n",
    "project_root = '/Users/arpitkapoor/Library/CloudStorage/OneDrive-UNSW/Shared/Projects/10_Katana/04_groundwater/GW_SciML/'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.data.plane_dataset import GWPlaneDatasetFromFiles\n",
    "from src.data.batch_sampler import PatchBatchSampler\n",
    "from src.models import GFNO\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe07287",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95445680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Data path\n",
    "data_dir = '/Users/arpitkapoor/data/GW/2d_plane_sequences'\n",
    "\n",
    "# Device configuration - automatically use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model parameters\n",
    "coord_dim = 3  # 3D: S, Z, T\n",
    "n_target_cols = 2  # head and mass_concentration\n",
    "\n",
    "# GNO parameters\n",
    "gno_radius = 0.15\n",
    "gno_out_channels = n_target_cols\n",
    "gno_channel_mlp_layers = [16, 32, 16]\n",
    "\n",
    "# FNO parameters\n",
    "fno_input_channels = coord_dim + n_target_cols + 2  # coordinates + target variables\n",
    "fno_n_layers = 4\n",
    "fno_n_modes = (6, 8, 8)  # 3D modes (S, Z, T)\n",
    "fno_hidden_channels = 64\n",
    "lifting_channels = 64\n",
    "out_channels = n_target_cols\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64  # Adjust based on GPU memory\n",
    "# num_workers = None  # For parallel data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710ce11",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b92096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /Users/arpitkapoor/data/GW/2d_plane_sequences...\n",
      "Initialized GWPlaneDatasetFromFiles with 3712 sequences across 32 planes\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Total sequences: 3712\n",
      "\n",
      "Sample data shapes:\n",
      "  plane_id: 0\n",
      "  input_geom: torch.Size([5216, 3]) (dtype: torch.float32)\n",
      "  input_data: torch.Size([5216, 2]) (dtype: torch.float32)\n",
      "  latent_geom: torch.Size([16, 32, 32, 3]) (dtype: torch.float32)\n",
      "  latent_features: torch.Size([16, 32, 32, 7]) (dtype: torch.float32)\n",
      "  output_latent_geom: torch.Size([16, 32, 32, 3]) (dtype: torch.float32)\n",
      "  output_latent_features: torch.Size([16, 32, 32, 2]) (dtype: torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset from saved files\n",
    "print(f\"Loading dataset from {data_dir}...\")\n",
    "dataset = GWPlaneDatasetFromFiles(\n",
    "    data_dir=data_dir,\n",
    "    fill_nan_value=-999.0\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Total sequences: {len(dataset)}\")\n",
    "\n",
    "# Check a sample\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample data shapes:\")\n",
    "for key, value in sample.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        print(f\"  {key}: {value.shape} (dtype: {value.dtype})\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da62fe7",
   "metadata": {},
   "source": [
    "## Create Batch Sampler and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef53c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batch sampler...\n",
      "Building patch groups (one-time operation)...\n",
      "Building plane_ids cache...\n",
      "Cached 3712 plane_ids\n",
      "Found 32 patches with 3712 total samples\n",
      "Patch sizes: min=116, max=116, avg=116.0\n",
      "Pre-built 64 batches\n",
      "Batch sampler created:\n",
      "  Total batches: 64\n",
      "  Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "# Create batch sampler (ensures samples from same plane are batched together)\n",
    "print(\"Creating batch sampler...\")\n",
    "batch_sampler = PatchBatchSampler(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle_within_batches=True,\n",
    "    shuffle_patches=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Batch sampler created:\")\n",
    "print(f\"  Total batches: {len(batch_sampler)}\")\n",
    "print(f\"  Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating DataLoader...\n",
      "DataLoader created with 64 batches\n",
      "Pin memory: False (enabled for faster GPU transfer)\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "print(\"\\nCreating DataLoader...\")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_sampler=batch_sampler,\n",
    "    # num_workers=num_workers,\n",
    "    pin_memory=True if device.type == 'cuda' else False  # Faster GPU transfer\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created with {len(dataloader)} batches\")\n",
    "print(f\"Pin memory: {dataloader.pin_memory} (enabled for faster GPU transfer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f7900",
   "metadata": {},
   "source": [
    "## Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e03779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader - fetching first batch...\n",
      "\n",
      "Batch details:\n",
      "  Batch size: 64\n",
      "  Plane IDs: [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26]\n",
      "  Unique planes: [26] (should be single plane)\n",
      "\n",
      "Batch tensor shapes:\n",
      "  input_geom: torch.Size([64, 320, 3])\n",
      "  input_data: torch.Size([64, 320, 2])\n",
      "  latent_geom: torch.Size([64, 16, 32, 32, 3])\n",
      "  latent_features: torch.Size([64, 16, 32, 32, 7])\n",
      "  output_latent_geom: torch.Size([64, 16, 32, 32, 3])\n",
      "  output_latent_features: torch.Size([64, 16, 32, 32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Fetch and inspect first batch\n",
    "print(\"Testing DataLoader - fetching first batch...\\n\")\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "print(f\"Batch details:\")\n",
    "print(f\"  Batch size: {len(batch['plane_id'])}\")\n",
    "print(f\"  Plane IDs: {batch['plane_id'].numpy()}\")\n",
    "print(f\"  Unique planes: {torch.unique(batch['plane_id']).numpy()} (should be single plane)\")\n",
    "print(f\"\\nBatch tensor shapes:\")\n",
    "print(f\"  input_geom: {batch['input_geom'].shape}\")\n",
    "print(f\"  input_data: {batch['input_data'].shape}\")\n",
    "print(f\"  latent_geom: {batch['latent_geom'].shape}\")\n",
    "print(f\"  latent_features: {batch['latent_features'].shape}\")\n",
    "print(f\"  output_latent_geom: {batch['output_latent_geom'].shape}\")\n",
    "print(f\"  output_latent_features: {batch['output_latent_features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9957c",
   "metadata": {},
   "source": [
    "## Initialize GFNO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d03e23f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GFNO model...\n",
      "\n",
      "Model created successfully!\n",
      "Total parameters: 7,910,180\n",
      "Trainable parameters: 7,910,180\n",
      "Model device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create GFNO model\n",
    "print(\"Initializing GFNO model...\")\n",
    "\n",
    "model = GFNO(\n",
    "    gno_coord_dim=coord_dim,\n",
    "    gno_radius=gno_radius,\n",
    "    gno_out_channels=gno_out_channels,\n",
    "    gno_channel_mlp_layers=gno_channel_mlp_layers,\n",
    "    latent_feature_channels=fno_input_channels,  # X, Y, head, mass_conc\n",
    "    fno_n_layers=fno_n_layers,\n",
    "    fno_n_modes=fno_n_modes,\n",
    "    fno_hidden_channels=fno_hidden_channels,\n",
    "    lifting_channels=lifting_channels,\n",
    "    out_channels=out_channels\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ec6b4",
   "metadata": {},
   "source": [
    "## Test Forward Pass on Single Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47ef87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass on a single batch...\n",
      "\n",
      "Input shapes (on cpu):\n",
      "  input_geom: torch.Size([64, 320, 3])\n",
      "  input_data: torch.Size([64, 320, 2])\n",
      "  latent_geom: torch.Size([64, 16, 32, 32, 3])\n",
      "  latent_features: torch.Size([64, 16, 32, 32, 7])\n",
      "\n",
      "Running forward pass...\n",
      "\n",
      "Forward pass complete!\n",
      "Time taken: 13.2065 seconds\n",
      "\n",
      "Output shape: torch.Size([64, 16, 32, 32, 2])\n",
      "Expected shape: torch.Size([64, 16, 32, 32, 2])\n",
      "\n",
      "Output statistics:\n",
      "  Min: -270.095184\n",
      "  Max: 338.677338\n",
      "  Mean: -21.460239\n",
      "  Std: 124.285980\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass on a single batch\n",
    "print(\"Running forward pass on a single batch...\\n\")\n",
    "\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get first batch\n",
    "    batch = next(iter(dataloader))\n",
    "    \n",
    "    # Move batch to device\n",
    "    input_geom = batch['input_geom'].to(device)\n",
    "    input_data = batch['input_data'].to(device)\n",
    "    latent_geom = batch['latent_geom'].to(device)\n",
    "    latent_features = batch['latent_features'].to(device)\n",
    "    output_latent_features = batch['output_latent_features'].to(device)\n",
    "    \n",
    "    print(f\"Input shapes (on {device}):\")\n",
    "    print(f\"  input_geom: {input_geom.shape}\")\n",
    "    print(f\"  input_data: {input_data.shape}\")\n",
    "    print(f\"  latent_geom: {latent_geom.shape}\")\n",
    "    print(f\"  latent_features: {latent_features.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    print(f\"\\nRunning forward pass...\")\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    predictions = model(\n",
    "        input_geom=input_geom,\n",
    "        x=input_data,\n",
    "        latent_queries=latent_geom,\n",
    "        latent_features=latent_features\n",
    "    )\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.synchronize()  # Wait for GPU to finish\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nForward pass complete!\")\n",
    "    print(f\"Time taken: {elapsed_time:.4f} seconds\")\n",
    "    print(f\"\\nOutput shape: {predictions.shape}\")\n",
    "    print(f\"Expected shape: {output_latent_features.shape}\")\n",
    "    print(f\"\\nOutput statistics:\")\n",
    "    print(f\"  Min: {predictions.min().item():.6f}\")\n",
    "    print(f\"  Max: {predictions.max().item():.6f}\")\n",
    "    print(f\"  Mean: {predictions.mean().item():.6f}\")\n",
    "    print(f\"  Std: {predictions.std().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ffb082",
   "metadata": {},
   "source": [
    "## Test Forward Pass on Multiple Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd37c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass on multiple batches...\n",
      "\n",
      "Batch 1/5: 12.6202s, plane_id=26, output_shape=torch.Size([64, 16, 32, 32, 2])\n",
      "Batch 2/5: 12.9709s, plane_id=29, output_shape=torch.Size([64, 16, 32, 32, 2])\n",
      "Batch 3/5: 21.5430s, plane_id=0, output_shape=torch.Size([64, 16, 32, 32, 2])\n",
      "Batch 4/5: 12.4956s, plane_id=22, output_shape=torch.Size([64, 16, 32, 32, 2])\n",
      "Batch 5/5: 10.7889s, plane_id=2, output_shape=torch.Size([52, 16, 32, 32, 2])\n",
      "\n",
      "Summary:\n",
      "  Total time: 70.4186s\n",
      "  Average time per batch: 14.0837s\n",
      "  Min time: 10.7889s\n",
      "  Max time: 21.5430s\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass on multiple batches\n",
    "print(\"Running forward pass on multiple batches...\\n\")\n",
    "\n",
    "model.eval()\n",
    "num_test_batches = 5\n",
    "\n",
    "total_time = 0\n",
    "batch_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= num_test_batches:\n",
    "            break\n",
    "        \n",
    "        # Move to device\n",
    "        input_geom = batch['input_geom'].to(device)\n",
    "        input_data = batch['input_data'].to(device)\n",
    "        latent_geom = batch['latent_geom'].to(device)\n",
    "        latent_features = batch['latent_features'].to(device)\n",
    "        \n",
    "        # Time forward pass\n",
    "        start_time = time.time()\n",
    "        \n",
    "        predictions = model(\n",
    "            input_geom=input_geom,\n",
    "            x=input_data,\n",
    "            latent_queries=latent_geom,\n",
    "            latent_features=latent_features\n",
    "        )\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        batch_times.append(elapsed)\n",
    "        total_time += elapsed\n",
    "        \n",
    "        print(f\"Batch {i+1}/{num_test_batches}: {elapsed:.4f}s, \"\n",
    "              f\"plane_id={torch.unique(batch['plane_id']).item()}, \"\n",
    "              f\"output_shape={predictions.shape}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total time: {total_time:.4f}s\")\n",
    "print(f\"  Average time per batch: {np.mean(batch_times):.4f}s\")\n",
    "print(f\"  Min time: {np.min(batch_times):.4f}s\")\n",
    "print(f\"  Max time: {np.max(batch_times):.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc6e91",
   "metadata": {},
   "source": [
    "## Memory Usage (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70fe8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU mode - no GPU memory tracking\n"
     ]
    }
   ],
   "source": [
    "# Check GPU memory usage\n",
    "if device.type == 'cuda':\n",
    "    print(\"GPU Memory Usage:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"  Max allocated: {torch.cuda.max_memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CPU mode - no GPU memory tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb6038",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8548067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "================================================================================\n",
      "GFNO(\n",
      "  (gno): GNOBlock(\n",
      "    (pos_embedding): SinusoidalEmbedding()\n",
      "    (neighbor_search): NeighborSearch()\n",
      "    (integral_transform): IntegralTransform(\n",
      "      (channel_mlp): LinearChannelMLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Linear(in_features=384, out_features=16, bias=True)\n",
      "          (1): Linear(in_features=16, out_features=32, bias=True)\n",
      "          (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (3): Linear(in_features=16, out_features=2, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x SpectralConv(\n",
      "        (weight): ModuleList(\n",
      "          (0): ComplexDenseTensor(shape=torch.Size([64, 64, 6, 8, 5]), rank=None)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lifting): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (projection): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 2, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "\n",
      "Parameter count by component:\n",
      "--------------------------------------------------------------------------------\n",
      "gno                           :           7,266 parameters\n",
      "fno_blocks                    :       7,880,960 parameters\n",
      "lifting                       :           4,800 parameters\n",
      "projection                    :          17,154 parameters\n",
      "--------------------------------------------------------------------------------\n",
      "Total                         :       7,910,180 parameters\n"
     ]
    }
   ],
   "source": [
    "# Print model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(\"=\" * 80)\n",
    "print(model)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Print parameter count by layer\n",
    "print(\"\\nParameter count by component:\")\n",
    "print(\"-\" * 80)\n",
    "for name, module in model.named_children():\n",
    "    num_params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name:30s}: {num_params:>15,} parameters\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Total':30s}: {total_params:>15,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73baf8b",
   "metadata": {},
   "source": [
    "## Success! âœ…\n",
    "\n",
    "The model successfully performed forward passes on batched data. You can now:\n",
    "\n",
    "1. **Train the model** by adding a training loop with optimizer and loss function\n",
    "2. **Adjust batch size** based on available GPU memory\n",
    "3. **Experiment with model parameters** to optimize performance\n",
    "4. **Add validation loop** to monitor model performance\n",
    "\n",
    "Next steps:\n",
    "- Create a training script using this notebook as a template\n",
    "- Implement proper train/validation split\n",
    "- Add checkpointing and logging\n",
    "- Monitor metrics and visualize predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
