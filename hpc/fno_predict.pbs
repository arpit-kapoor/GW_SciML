#!/bin/bash
#PBS -N FNO_Predict
#PBS -l select=1:ncpus=4:mem=16gb:ngpus=1:gpu_model=A100
#PBS -l walltime=2:00:00
#PBS -o /dev/null
#PBS -e /dev/null
#PBS -m abe

# Redirect output to log file
LOG_DIR="/srv/scratch/z5370003/projects/src/04_groundwater/variable_density/logs"
CONFIG_NAME="${CONFIG:-default}"
LOG_FILE="${LOG_DIR}/fno_${CONFIG_NAME}_predict_${PBS_JOBID}.log"
exec > "$LOG_FILE" 2>&1
echo "Job started on $(hostname) at $(date)"
echo "Job ID: $PBS_JOBID"

# FNOInterpolate prediction with dynamic arguments
#
# Usage: Called via submit_fno.sh with --predict flag
#   ./submit_fno.sh default --predict
#   ./submit_fno.sh var_loss --predict
#
# Environment variables:
#   CONFIG        : Configuration name (determines output directory)
#   MODEL_PATH    : Path to model checkpoint
#   PRED_ARGS     : Prediction arguments (constructed by submit_fno.sh)

cd $PBS_O_WORKDIR/..

# Environment
PYTHON_ENV="/srv/scratch/z5370003/miniconda3/envs/torch-env/bin/python"
PREDICTIONS_BASE_DIR="/srv/scratch/z5370003/projects/results/04_groundwater/variable_density/FNO_predictions"

# Determine config name (defaults to 'default' if not specified)
CONFIG_NAME="${CONFIG:-default}"

# Create config-specific predictions directory
CONFIG_PREDICTIONS_DIR="${PREDICTIONS_BASE_DIR}/${CONFIG_NAME}"
mkdir -p "$CONFIG_PREDICTIONS_DIR"

echo "=========================================="
echo "FNOInterpolate Prediction Job"
echo "=========================================="
echo "Config: $CONFIG_NAME"
echo "Predictions directory: $CONFIG_PREDICTIONS_DIR"
echo "Job ID: $PBS_JOBID"
echo "Start time: $(date)"
echo "=========================================="
echo ""
echo "GPU Information:"
nvidia-smi --query-gpu=index,name,driver_version,memory.total,memory.free --format=csv
echo "=========================================="

# Get model path and prediction args from environment
if [ -z "$MODEL_PATH" ]; then
    echo "Error: MODEL_PATH not provided"
    exit 1
fi

if [ -z "$PRED_ARGS_B64" ]; then
    echo "Error: PRED_ARGS_B64 not provided"
    exit 1
fi

# Decode base64-encoded prediction arguments
PRED_ARGS=$(echo "$PRED_ARGS_B64" | base64 -d)

# Verify model path exists
if [ ! -f "$MODEL_PATH" ]; then
    echo "Error: Model checkpoint not found: $MODEL_PATH"
    exit 1
fi

# Append results directory to prediction args
PREDICT_ARGS="$PRED_ARGS --results-dir $CONFIG_PREDICTIONS_DIR"

# Display final command
echo ""
echo "Model checkpoint: $MODEL_PATH"
echo "Prediction arguments: $PREDICT_ARGS"
echo ""
echo "=========================================="
echo ""
echo "Executing command:"
echo "$PYTHON_ENV -u fno_predict.py $PREDICT_ARGS"
echo ""

# Execute prediction with unbuffered output (-u flag)
$PYTHON_ENV -u fno_predict.py $PREDICT_ARGS
EXIT_CODE=$?

echo ""
echo "=========================================="
echo "Prediction generation completed"
echo "Exit code: $EXIT_CODE"
echo "End time: $(date)"
echo "Predictions saved to: $CONFIG_PREDICTIONS_DIR"
echo "=========================================="

# PBS Resource Usage Summary
echo ""
echo "=========================================="
echo "PBS Resource Usage Summary"
echo "=========================================="
qstat -f $PBS_JOBID 2>/dev/null | grep -E '(Job_Name|resources_used|Exit_status|exec_host)' || echo "Job completed, stats no longer available"
echo ""
echo "Final GPU Status:"
nvidia-smi --query-gpu=index,name,utilization.gpu,utilization.memory,memory.used,memory.total,temperature.gpu --format=csv
echo "=========================================="

exit $EXIT_CODE
