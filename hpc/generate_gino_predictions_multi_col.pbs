#!/bin/bash
#PBS -N GINO_predictions_multi
#PBS -l select=1:ncpus=4:mem=16gb:ngpus=1
#PBS -l walltime=02:00:00
#PBS -m abe
#PBS -j oe
#PBS -o /srv/scratch/z5370003/projects/src/04_groundwater/variable_density/logs/gino_predictions_multi_col.log

# USAGE:
# Directory structure follows multi-column training: RESULTS_BASE_DIR/multi_col/TARGET_COLS_ID/EXPERIMENT_NAME/gino_multi_TIMESTAMP/
# Predictions can be stored either:
# 1. With model (STORE_WITH_MODEL=true):  RESULTS_BASE_DIR/multi_col/TARGET_COLS_ID/EXPERIMENT_NAME/gino_multi_TIMESTAMP/predictions/
# 2. Separately (default):                PREDICTIONS_BASE_DIR/multi_col/TARGET_COLS_ID/EXPERIMENT_NAME/gino_multi_TIMESTAMP/
# 
# BASIC USAGE:
# Default experiment:               qsub generate_gino_predictions_multi_col.pbs
# Different target columns:         qsub -v TARGET_COLS="head pressure" generate_gino_predictions_multi_col.pbs
# Different experiment:             qsub -v EXPERIMENT_NAME=exp_lr1e3_cos_bs256 generate_gino_predictions_multi_col.pbs
# Different checkpoint:             qsub -v CHECKPOINT=checkpoint_epoch_0050.pth generate_gino_predictions_multi_col.pbs
# Store with model:                qsub -v STORE_WITH_MODEL=true generate_gino_predictions_multi_col.pbs
# Custom predictions dir:           qsub -v PREDICTIONS_BASE_DIR=/path/to/predictions generate_gino_predictions_multi_col.pbs
# 
# EXAMPLES:
# - Default (2 vars, separate):     PREDICTIONS_BASE_DIR/multi_col/mass_conc_head/exp_lr5e4_cos_bs128/gino_multi_TIMESTAMP/
# - Store with model:              RESULTS_BASE_DIR/multi_col/mass_conc_head/exp_lr5e4_cos_bs128/gino_multi_TIMESTAMP/predictions/
# - 3 variables:                   PREDICTIONS_BASE_DIR/multi_col/mass_conc_head_press/exp_lr5e4_cos_bs128/gino_multi_TIMESTAMP/
# - Custom experiment:             PREDICTIONS_BASE_DIR/multi_col/mass_conc_head/my_custom_experiment/gino_multi_TIMESTAMP/

# Change to the directory from which the job was submitted
cd $PBS_O_WORKDIR/..

# Set up base directories and Python environment
RESULTS_BASE_DIR="${RESULTS_BASE_DIR:-/srv/scratch/z5370003/projects/results/04_groundwater/variable_density/GINO}"
PREDICTIONS_BASE_DIR="${PREDICTIONS_BASE_DIR:-/srv/scratch/z5370003/projects/results/04_groundwater/variable_density/GINO_predictions}"
PYTHON_ENV="/srv/scratch/z5370003/miniconda3/envs/torch-env/bin/python"
BASE_DATA_DIR="/srv/scratch/z5370003/projects/data/groundwater/FEFLOW/coastal/variable_density"

# Parameters (matching training configuration)
BATCH_SIZE="${BATCH_SIZE:-128}"
INPUT_WINDOW="${INPUT_WINDOW:-5}"
OUTPUT_WINDOW="${OUTPUT_WINDOW:-5}"

# Multi-column specific: TARGET_COLS is a space-separated list
# Default: mass_concentration and head
TARGET_COLS="${TARGET_COLS:-mass_concentration head}"

# Experiment name (should match training experiment)
EXPERIMENT_NAME="${EXPERIMENT_NAME:-exp_lr5e4_exp_bs128}"  # Default experiment
CHECKPOINT="${CHECKPOINT:-latest_checkpoint.pth}"  # Default to latest checkpoint

# Control where predictions are stored
STORE_WITH_MODEL="${STORE_WITH_MODEL:-false}"

# Function to create a short identifier for target columns
create_target_cols_id() {
    local cols="$1"
    local id=""
    
    for col in $cols; do
        case "$col" in
            mass_concentration)
                id="${id}_mass_conc"
                ;;
            head)
                id="${id}_head"
                ;;
            pressure)
                id="${id}_press"
                ;;
            *)
                # For unknown columns, use first 4 chars
                id="${id}_${col:0:4}"
                ;;
        esac
    done
    
    # Remove leading underscore
    echo "${id:1}"
}

# Create target columns identifier
TARGET_COLS_ID=$(create_target_cols_id "$TARGET_COLS")

# Set up experiment directories
MULTI_COL_RESULTS_DIR="$RESULTS_BASE_DIR/multi_col"
TARGET_RESULTS_DIR="$MULTI_COL_RESULTS_DIR/$TARGET_COLS_ID"
EXPERIMENT_DIR="$TARGET_RESULTS_DIR/$EXPERIMENT_NAME"

# Find the most recent training run
LATEST_RESULTS_DIR=$(find "$EXPERIMENT_DIR" -maxdepth 1 -type d -name "gino_multi_*" | sort | tail -1)

if [ -z "$LATEST_RESULTS_DIR" ]; then
    echo "Error: No training runs found for experiment '$EXPERIMENT_NAME' with target columns '$TARGET_COLS_ID'"
    echo ""
    echo "Available experiments for target columns '$TARGET_COLS_ID':"
    if [ -d "$TARGET_RESULTS_DIR" ]; then
        find "$TARGET_RESULTS_DIR" -maxdepth 1 -type d -name "exp_*" | sed 's|.*/||' | sort
    else
        echo "  (None - directory does not exist)"
    fi
    echo ""
    echo "Available target column combinations:"
    if [ -d "$MULTI_COL_RESULTS_DIR" ]; then
        find "$MULTI_COL_RESULTS_DIR" -maxdepth 1 -type d ! -path "$MULTI_COL_RESULTS_DIR" | sed 's|.*/||' | sort
    else
        echo "  (None - directory does not exist)"
    fi
    exit 1
fi

# Construct model path
MODEL_PATH="$LATEST_RESULTS_DIR/checkpoints/$CHECKPOINT"

if [ ! -f "$MODEL_PATH" ]; then
    echo "Error: Model checkpoint not found: $MODEL_PATH"
    echo "Available checkpoints:"
    ls -1 "$LATEST_RESULTS_DIR/checkpoints/"
    exit 1
fi

# Set up predictions directory based on configuration
if [ "$STORE_WITH_MODEL" = "true" ]; then
    # Store predictions alongside model in experiment directory
    PREDICTIONS_DIR="$LATEST_RESULTS_DIR/predictions"
else
    # Store in separate predictions directory with experiment structure
    PREDICTIONS_DIR="$PREDICTIONS_BASE_DIR/multi_col/$TARGET_COLS_ID/$EXPERIMENT_NAME/$(basename $CHECKPOINT)"
fi

# Create predictions directory
mkdir -p "$PREDICTIONS_DIR"

echo "=========================================="
echo "GINO Multi-Column Predictions Configuration"
echo "=========================================="
echo "Target columns: $TARGET_COLS"
echo "Target columns ID: $TARGET_COLS_ID"
echo "Experiment: $EXPERIMENT_NAME"
echo "Model path: $MODEL_PATH"
echo "Predictions directory: $PREDICTIONS_DIR"
echo "Storing predictions with model: $STORE_WITH_MODEL"
echo "=========================================="

# Run the prediction script
$PYTHON_ENV generate_gino_predictions_multi_col.py \
    --model-path "$MODEL_PATH" \
    --base-data-dir "$BASE_DATA_DIR" \
    --results-dir "$PREDICTIONS_DIR" \
    --target-cols "$TARGET_COLS" \
    --input-window-size "$INPUT_WINDOW" \
    --output-window-size "$OUTPUT_WINDOW" \
    --batch-size "$BATCH_SIZE" \
    --device auto

echo ""
echo "=========================================="
echo "Prediction generation completed!"
echo "Results saved to: $PREDICTIONS_DIR"
echo "=========================================="




